{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import data, io, filters, color, exposure\n",
    "from skimage.transform import rotate\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='/Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_by_pattern(directory_path, destination_path, regex_pattern):\n",
    "    \"\"\"\n",
    "    Copies files from the source directory to the destination directory based on a regex pattern.\n",
    "\n",
    "    Args:\n",
    "    directory_path (str): Path to the directory containing the files.\n",
    "    destination_path (str): Directory where the copies will be stored.\n",
    "    regex_pattern (str): Regular expression pattern to match filenames.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Compile the regex pattern\n",
    "    pattern = re.compile(regex_pattern)\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "    # Initialize a counter for copied files\n",
    "    copied_files_count = 0\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the filename matches the pattern\n",
    "        if pattern.match(filename):\n",
    "            # Path of the current file\n",
    "            current_file_path = os.path.join(directory_path, filename)\n",
    "            # Path where the file will be copied\n",
    "            destination_file_path = os.path.join(destination_path, filename)\n",
    "            # Copy the file\n",
    "            shutil.copy2(current_file_path, destination_file_path)\n",
    "            copied_files_count += 1\n",
    "            print(f'Copied: {filename}')\n",
    "\n",
    "    # Print the result\n",
    "    print(f'All matching files have been copied to {destination_path}. Total files copied: {copied_files_count}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = [\n",
    "    \"spherocyte\",\n",
    "    \"echinocyte\",\n",
    "    \"keratocytes\",\n",
    "    \"multilobate_cells\",\n",
    "    \"cell_clusters\",\n",
    "    \"knizocytes\",\n",
    "    \"multilobate_cells\",\n",
    "    \"acanthocytes\",\n",
    "    \"stomatocyte\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: -1.00_spherocyte000043.tif\n",
      "Copied: -1.00_spherocyte000044.tif\n",
      "Copied: -1.00_spherocyte000045.tif\n",
      "Copied: -1.00_spherocyte000046.tif\n",
      "Copied: -1.00_spherocyte000047.tif\n",
      "Copied: -1.00_spherocyte000048.tif\n",
      "Copied: -1.00_spherocyte000049.tif\n",
      "Copied: -1.00_spherocyte000050.tif\n",
      "Copied: -1.00_spherocyte000051.tif\n",
      "Copied: -1.00_spherocyte000052.tif\n",
      "Copied: -1.00_spherocyte000053.tif\n",
      "Copied: -1.00_spherocyte000054.tif\n",
      "Copied: -1.00_spherocyte000055.tif\n",
      "Copied: -1.00_spherocyte000056.tif\n",
      "Copied: -1.00_spherocyte000057.tif\n",
      "Copied: -1.00_spherocyte000058.tif\n",
      "Copied: -1.00_spherocyte000059.tif\n",
      "Copied: -1.00_spherocyte000060.tif\n",
      "Copied: -1.00_spherocyte000061.tif\n",
      "Copied: -1.00_spherocyte000062.tif\n",
      "Copied: -1.00_spherocyte000063.tif\n",
      "Copied: -1.00_spherocyte000064.tif\n",
      "Copied: -1.00_spherocyte000065.tif\n",
      "Copied: -1.00_spherocyte000066.tif\n",
      "Copied: -1.00_spherocyte000067.tif\n",
      "Copied: -1.00_spherocyte000068.tif\n",
      "Copied: -1.00_spherocyte000069.tif\n",
      "Copied: -1.00_spherocyte000070.tif\n",
      "Copied: -1.00_spherocyte000071.tif\n",
      "Copied: -1.00_spherocyte000072.tif\n",
      "Copied: -1.00_spherocyte000073.tif\n",
      "Copied: -1.00_spherocyte000074.tif\n",
      "Copied: -1.00_spherocyte000075.tif\n",
      "Copied: -1.00_spherocyte000076.tif\n",
      "Copied: -1.00_spherocyte000077.tif\n",
      "Copied: -1.00_spherocyte000078.tif\n",
      "Copied: -1.00_spherocyte000079.tif\n",
      "Copied: -1.00_spherocyte000080.tif\n",
      "Copied: -1.00_spherocyte000081.tif\n",
      "Copied: -1.00_spherocyte000082.tif\n",
      "Copied: -1.00_spherocyte000083.tif\n",
      "Copied: -1.00_spherocyte000084.tif\n",
      "Copied: -1.00_spherocyte000085.tif\n",
      "Copied: -1.00_spherocyte000086.tif\n",
      "Copied: -1.00_spherocyte000087.tif\n",
      "Copied: -1.00_spherocyte000088.tif\n",
      "Copied: -1.00_spherocyte000089.tif\n",
      "Copied: -1.00_spherocyte000090.tif\n",
      "Copied: -1.00_spherocyte000091.tif\n",
      "Copied: -1.00_spherocyte000092.tif\n",
      "Copied: -1.00_spherocyte000093.tif\n",
      "Copied: -1.00_spherocyte000094.tif\n",
      "Copied: -1.00_spherocyte000095.tif\n",
      "Copied: -1.00_spherocyte000096.tif\n",
      "Copied: -1.00_spherocyte000097.tif\n",
      "Copied: -1.00_spherocyte000098.tif\n",
      "Copied: -1.00_spherocyte000099.tif\n",
      "Copied: -1.00_spherocyte000100.tif\n",
      "Copied: -1.00_spherocyte000101.tif\n",
      "Copied: -1.00_spherocyte000102.tif\n",
      "Copied: -1.00_spherocyte000103.tif\n",
      "Copied: -1.00_spherocyte000104.tif\n",
      "Copied: -1.00_spherocyte000105.tif\n",
      "Copied: -1.00_spherocyte000106.tif\n",
      "Copied: -1.00_spherocyte000107.tif\n",
      "Copied: -1.00_spherocyte000108.tif\n",
      "Copied: -1.00_spherocyte000109.tif\n",
      "Copied: -1.00_spherocyte000110.tif\n",
      "Copied: -1.00_spherocyte000111.tif\n",
      "Copied: -1.00_spherocyte000112.tif\n",
      "Copied: -1.00_spherocyte000113.tif\n",
      "Copied: -1.00_spherocyte000114.tif\n",
      "Copied: -1.00_spherocyte000115.tif\n",
      "Copied: -1.00_spherocyte000116.tif\n",
      "Copied: -1.00_spherocyte000117.tif\n",
      "Copied: -1.00_spherocyte000118.tif\n",
      "Copied: -1.00_spherocyte000119.tif\n",
      "Copied: -1.00_spherocyte000120.tif\n",
      "Copied: -1.00_spherocyte000121.tif\n",
      "Copied: -1.00_spherocyte000122.tif\n",
      "Copied: -1.00_spherocyte000123.tif\n",
      "Copied: -1.00_spherocyte000124.tif\n",
      "Copied: -1.00_spherocyte000125.tif\n",
      "Copied: -1.00_spherocyte000126.tif\n",
      "Copied: -1.00_spherocyte000127.tif\n",
      "Copied: -1.00_spherocyte000128.tif\n",
      "Copied: -1.00_spherocyte000129.tif\n",
      "Copied: -1.00_spherocyte000130.tif\n",
      "Copied: -1.00_spherocyte000131.tif\n",
      "Copied: -1.00_spherocyte000132.tif\n",
      "Copied: -1.00_spherocyte000133.tif\n",
      "Copied: -1.00_spherocyte000134.tif\n",
      "Copied: -1.00_spherocyte000135.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/spherocyte. Total files copied: 93\n",
      "Copied: 0.33_echinocyte_I000312.tif\n",
      "Copied: 0.33_echinocyte_I000313.tif\n",
      "Copied: 0.33_echinocyte_I000314.tif\n",
      "Copied: 0.33_echinocyte_I000315.tif\n",
      "Copied: 0.33_echinocyte_I000316.tif\n",
      "Copied: 0.33_echinocyte_I000317.tif\n",
      "Copied: 0.33_echinocyte_I000318.tif\n",
      "Copied: 0.33_echinocyte_I000319.tif\n",
      "Copied: 0.33_echinocyte_I000320.tif\n",
      "Copied: 0.33_echinocyte_I000321.tif\n",
      "Copied: 0.33_echinocyte_I000322.tif\n",
      "Copied: 0.33_echinocyte_I000323.tif\n",
      "Copied: 0.33_echinocyte_I000324.tif\n",
      "Copied: 0.33_echinocyte_I000325.tif\n",
      "Copied: 0.33_echinocyte_I000326.tif\n",
      "Copied: 0.33_echinocyte_I000327.tif\n",
      "Copied: 0.33_echinocyte_I000328.tif\n",
      "Copied: 0.33_echinocyte_I000329.tif\n",
      "Copied: 0.33_echinocyte_I000330.tif\n",
      "Copied: 0.33_echinocyte_I000331.tif\n",
      "Copied: 0.33_echinocyte_I000332.tif\n",
      "Copied: 0.33_echinocyte_I000333.tif\n",
      "Copied: 0.33_echinocyte_I000334.tif\n",
      "Copied: 0.33_echinocyte_I000335.tif\n",
      "Copied: 0.33_echinocyte_I000336.tif\n",
      "Copied: 0.33_echinocyte_I000337.tif\n",
      "Copied: 0.33_echinocyte_I000338.tif\n",
      "Copied: 0.33_echinocyte_I000339.tif\n",
      "Copied: 0.33_echinocyte_I000340.tif\n",
      "Copied: 0.33_echinocyte_I000341.tif\n",
      "Copied: 0.33_echinocyte_I000342.tif\n",
      "Copied: 0.33_echinocyte_I000343.tif\n",
      "Copied: 0.33_echinocyte_I000344.tif\n",
      "Copied: 0.33_echinocyte_I000345.tif\n",
      "Copied: 0.33_echinocyte_I000346.tif\n",
      "Copied: 0.33_echinocyte_I000347.tif\n",
      "Copied: 0.33_echinocyte_I000348.tif\n",
      "Copied: 0.33_echinocyte_I000349.tif\n",
      "Copied: 0.33_echinocyte_I000350.tif\n",
      "Copied: 0.33_echinocyte_I000351.tif\n",
      "Copied: 0.33_echinocyte_I000352.tif\n",
      "Copied: 0.33_echinocyte_I000353.tif\n",
      "Copied: 0.33_echinocyte_I000354.tif\n",
      "Copied: 0.33_echinocyte_I000355.tif\n",
      "Copied: 0.33_echinocyte_I000356.tif\n",
      "Copied: 0.33_echinocyte_I000357.tif\n",
      "Copied: 0.33_echinocyte_I000358.tif\n",
      "Copied: 0.67_echinocyte_II000359.tif\n",
      "Copied: 0.67_echinocyte_II000360.tif\n",
      "Copied: 0.67_echinocyte_II000361.tif\n",
      "Copied: 0.67_echinocyte_II000362.tif\n",
      "Copied: 0.67_echinocyte_II000363.tif\n",
      "Copied: 0.67_echinocyte_II000364.tif\n",
      "Copied: 0.67_echinocyte_II000365.tif\n",
      "Copied: 0.67_echinocyte_II000366.tif\n",
      "Copied: 0.67_echinocyte_II000367.tif\n",
      "Copied: 0.67_echinocyte_II000368.tif\n",
      "Copied: 0.67_echinocyte_II000369.tif\n",
      "Copied: 0.67_echinocyte_II000370.tif\n",
      "Copied: 0.67_echinocyte_II000371.tif\n",
      "Copied: 0.67_echinocyte_II000372.tif\n",
      "Copied: 0.67_echinocyte_II000373.tif\n",
      "Copied: 0.67_echinocyte_II000374.tif\n",
      "Copied: 0.67_echinocyte_II000375.tif\n",
      "Copied: 0.67_echinocyte_II000376.tif\n",
      "Copied: 0.67_echinocyte_II000377.tif\n",
      "Copied: 0.67_echinocyte_II000378.tif\n",
      "Copied: 0.67_echinocyte_II000379.tif\n",
      "Copied: 0.67_echinocyte_II000380.tif\n",
      "Copied: 0.67_echinocyte_II000381.tif\n",
      "Copied: 0.67_echinocyte_II000382.tif\n",
      "Copied: 0.67_echinocyte_II000383.tif\n",
      "Copied: 0.67_echinocyte_II000384.tif\n",
      "Copied: 0.67_echinocyte_II000385.tif\n",
      "Copied: 0.67_echinocyte_II000386.tif\n",
      "Copied: 0.67_echinocyte_II000387.tif\n",
      "Copied: 0.67_echinocyte_II000388.tif\n",
      "Copied: 0.67_echinocyte_II000389.tif\n",
      "Copied: 0.67_echinocyte_II000390.tif\n",
      "Copied: 0.67_echinocyte_II000391.tif\n",
      "Copied: 0.67_echinocyte_II000392.tif\n",
      "Copied: 0.67_echinocyte_II000393.tif\n",
      "Copied: 0.67_echinocyte_II000394.tif\n",
      "Copied: 0.67_echinocyte_II000395.tif\n",
      "Copied: 0.67_echinocyte_II000396.tif\n",
      "Copied: 0.67_echinocyte_II000397.tif\n",
      "Copied: 0.67_echinocyte_II000398.tif\n",
      "Copied: 0.67_echinocyte_II000399.tif\n",
      "Copied: 0.67_echinocyte_II000400.tif\n",
      "Copied: 0.67_echinocyte_II000401.tif\n",
      "Copied: 0.67_echinocyte_II000402.tif\n",
      "Copied: 0.67_echinocyte_II000403.tif\n",
      "Copied: 0.67_echinocyte_II000404.tif\n",
      "Copied: 0.67_echinocyte_II000405.tif\n",
      "Copied: 0.67_echinocyte_II000406.tif\n",
      "Copied: 0.67_echinocyte_II000407.tif\n",
      "Copied: 0.67_echinocyte_II000408.tif\n",
      "Copied: 0.67_echinocyte_II000409.tif\n",
      "Copied: 0.67_echinocyte_II000410.tif\n",
      "Copied: 0.67_echinocyte_II000411.tif\n",
      "Copied: 0.67_echinocyte_II000412.tif\n",
      "Copied: 0.67_echinocyte_II000413.tif\n",
      "Copied: 0.67_echinocyte_II000414.tif\n",
      "Copied: 0.67_echinocyte_II000415.tif\n",
      "Copied: 0.67_echinocyte_II000416.tif\n",
      "Copied: 0.67_echinocyte_II000417.tif\n",
      "Copied: 0.67_echinocyte_II000418.tif\n",
      "Copied: 0.67_echinocyte_II000419.tif\n",
      "Copied: 0.67_echinocyte_II000420.tif\n",
      "Copied: 0.67_echinocyte_II000421.tif\n",
      "Copied: 0.67_echinocyte_II000422.tif\n",
      "Copied: 0.67_echinocyte_II000423.tif\n",
      "Copied: 0.67_echinocyte_II000424.tif\n",
      "Copied: 0.67_echinocyte_II000425.tif\n",
      "Copied: 0.67_echinocyte_II000426.tif\n",
      "Copied: 0.67_echinocyte_II000427.tif\n",
      "Copied: 0.67_echinocyte_II000428.tif\n",
      "Copied: 0.67_echinocyte_II000429.tif\n",
      "Copied: 0.67_echinocyte_II000430.tif\n",
      "Copied: 0.67_echinocyte_II000431.tif\n",
      "Copied: 0.67_echinocyte_II000432.tif\n",
      "Copied: 0.67_echinocyte_II000433.tif\n",
      "Copied: 0.67_echinocyte_II000434.tif\n",
      "Copied: 0.67_echinocyte_II000435.tif\n",
      "Copied: 1.00_echinocyte_III000436.tif\n",
      "Copied: 1.00_echinocyte_III000437.tif\n",
      "Copied: 1.00_echinocyte_III000438.tif\n",
      "Copied: 1.00_echinocyte_III000439.tif\n",
      "Copied: 1.00_echinocyte_III000440.tif\n",
      "Copied: 1.00_echinocyte_III000441.tif\n",
      "Copied: 1.00_echinocyte_III000442.tif\n",
      "Copied: 1.00_echinocyte_III000443.tif\n",
      "Copied: 1.00_echinocyte_III000444.tif\n",
      "Copied: 1.00_echinocyte_III000445.tif\n",
      "Copied: 1.00_echinocyte_III000446.tif\n",
      "Copied: 1.00_echinocyte_III000447.tif\n",
      "Copied: 1.00_echinocyte_III000448.tif\n",
      "Copied: 1.00_echinocyte_III000449.tif\n",
      "Copied: 1.00_echinocyte_III000450.tif\n",
      "Copied: 1.00_echinocyte_III000451.tif\n",
      "Copied: 1.00_echinocyte_III000452.tif\n",
      "Copied: 1.00_echinocyte_III000453.tif\n",
      "Copied: 1.00_echinocyte_III000454.tif\n",
      "Copied: 1.00_echinocyte_III000455.tif\n",
      "Copied: 1.00_echinocyte_III000456.tif\n",
      "Copied: 1.00_echinocyte_III000457.tif\n",
      "Copied: 1.00_echinocyte_III000458.tif\n",
      "Copied: 1.00_echinocyte_III000459.tif\n",
      "Copied: 1.00_echinocyte_III000460.tif\n",
      "Copied: 1.00_echinocyte_III000461.tif\n",
      "Copied: 1.00_echinocyte_III000462.tif\n",
      "Copied: 1.00_echinocyte_III000463.tif\n",
      "Copied: 1.00_echinocyte_III000464.tif\n",
      "Copied: 1.00_echinocyte_III000465.tif\n",
      "Copied: 1.00_echinocyte_III000466.tif\n",
      "Copied: 1.00_echinocyte_III000467.tif\n",
      "Copied: 1.00_echinocyte_III000468.tif\n",
      "Copied: 1.00_echinocyte_III000469.tif\n",
      "Copied: 1.00_echinocyte_III000470.tif\n",
      "Copied: 1.00_echinocyte_III000471.tif\n",
      "Copied: 1.00_echinocyte_III000472.tif\n",
      "Copied: 1.00_echinocyte_III000473.tif\n",
      "Copied: 1.00_echinocyte_III000474.tif\n",
      "Copied: 1.00_echinocyte_III000475.tif\n",
      "Copied: 1.00_echinocyte_III000476.tif\n",
      "Copied: 1.00_echinocyte_III000477.tif\n",
      "Copied: 1.00_echinocyte_III000478.tif\n",
      "Copied: 1.00_echinocyte_III000479.tif\n",
      "Copied: 1.00_echinocyte_III000480.tif\n",
      "Copied: 1.00_echinocyte_III000481.tif\n",
      "Copied: 1.00_echinocyte_III000482.tif\n",
      "Copied: 1.00_echinocyte_III000483.tif\n",
      "Copied: 1.00_echinocyte_III000484.tif\n",
      "Copied: 1.00_echinocyte_III000485.tif\n",
      "Copied: 1.00_echinocyte_III000486.tif\n",
      "Copied: 1.00_echinocyte_III000487.tif\n",
      "Copied: 1.00_echinocyte_III000488.tif\n",
      "Copied: 1.00_echinocyte_III000489.tif\n",
      "Copied: 1.00_echinocyte_III000490.tif\n",
      "Copied: 1.00_echinocyte_III000491.tif\n",
      "Copied: 1.00_echinocyte_III000492.tif\n",
      "Copied: 1.00_echinocyte_III000493.tif\n",
      "Copied: 1.00_echinocyte_III000494.tif\n",
      "Copied: 1.00_echinocyte_III000495.tif\n",
      "Copied: 1.00_echinocyte_III000496.tif\n",
      "Copied: 1.00_echinocyte_III000497.tif\n",
      "Copied: 1.00_echinocyte_III000498.tif\n",
      "Copied: 1.00_echinocyte_III000499.tif\n",
      "Copied: 1.00_echinocyte_III000500.tif\n",
      "Copied: 1.00_echinocyte_III000501.tif\n",
      "Copied: 1.00_echinocyte_III000502.tif\n",
      "Copied: 1.00_echinocyte_III000503.tif\n",
      "Copied: 1.00_echinocyte_III000504.tif\n",
      "Copied: 1.00_echinocyte_III000505.tif\n",
      "Copied: 1.00_echinocyte_III000506.tif\n",
      "Copied: 1.00_echinocyte_III000507.tif\n",
      "Copied: 1.00_echinocyte_III000508.tif\n",
      "Copied: 1.00_echinocyte_III000509.tif\n",
      "Copied: 1.00_echinocyte_III000510.tif\n",
      "Copied: 1.00_echinocyte_III000511.tif\n",
      "Copied: 1.00_echinocyte_III000512.tif\n",
      "Copied: 1.00_echinocyte_III000513.tif\n",
      "Copied: 1.00_echinocyte_III000514.tif\n",
      "Copied: 1.00_echinocyte_III000515.tif\n",
      "Copied: 1.00_echinocyte_III000516.tif\n",
      "Copied: 1.00_echinocyte_III000517.tif\n",
      "Copied: 1.00_echinocyte_III000518.tif\n",
      "Copied: 1.00_echinocyte_III000519.tif\n",
      "Copied: 1.00_echinocyte_III000520.tif\n",
      "Copied: 1.00_echinocyte_III000521.tif\n",
      "Copied: 1.00_echinocyte_III000522.tif\n",
      "Copied: 1.00_echinocyte_III000523.tif\n",
      "Copied: 1.00_echinocyte_III000524.tif\n",
      "Copied: 1.00_echinocyte_III000525.tif\n",
      "Copied: 1.00_echinocyte_III000526.tif\n",
      "Copied: 1.00_echinocyte_III000527.tif\n",
      "Copied: 1.00_echinocyte_III000528.tif\n",
      "Copied: 1.00_echinocyte_III000529.tif\n",
      "Copied: 1.00_echinocyte_III000530.tif\n",
      "Copied: 1.00_echinocyte_III000531.tif\n",
      "Copied: 1.00_echinocyte_III000532.tif\n",
      "Copied: 1.00_echinocyte_III000533.tif\n",
      "Copied: 1.00_echinocyte_III000534.tif\n",
      "Copied: 1.00_echinocyte_III000535.tif\n",
      "Copied: 1.00_echinocyte_III000536.tif\n",
      "Copied: 1.00_echinocyte_III000537.tif\n",
      "Copied: 1.00_echinocyte_III000538.tif\n",
      "Copied: 1.00_echinocyte_III000539.tif\n",
      "Copied: 1.00_echinocyte_III000540.tif\n",
      "Copied: 1.00_echinocyte_III000541.tif\n",
      "Copied: 1.00_echinocyte_III000542.tif\n",
      "Copied: 1.00_echinocyte_III000543.tif\n",
      "Copied: 1.00_echinocyte_III000544.tif\n",
      "Copied: 1.00_echinocyte_III000545.tif\n",
      "Copied: 1.00_echinocyte_III000546.tif\n",
      "Copied: 1.00_echinocyte_III000547.tif\n",
      "Copied: 1.00_echinocyte_III000548.tif\n",
      "Copied: 1.00_echinocyte_III000549.tif\n",
      "Copied: 1.00_echinocyte_III000550.tif\n",
      "Copied: 1.00_echinocyte_III000551.tif\n",
      "Copied: 1.00_echinocyte_III000552.tif\n",
      "Copied: 1.00_echinocyte_III000553.tif\n",
      "Copied: 1.00_echinocyte_III000554.tif\n",
      "Copied: 1.00_echinocyte_III000555.tif\n",
      "Copied: 1.00_echinocyte_III000556.tif\n",
      "Copied: 1.00_echinocyte_III000557.tif\n",
      "Copied: 1.00_echinocyte_III000558.tif\n",
      "Copied: 1.00_echinocyte_III000559.tif\n",
      "Copied: 1.00_echinocyte_III000560.tif\n",
      "Copied: 1.00_echinocyte_III000561.tif\n",
      "Copied: 1.00_echinocyte_III000562.tif\n",
      "Copied: 1.00_echinocyte_III000563.tif\n",
      "Copied: 1.00_echinocyte_III000564.tif\n",
      "Copied: 1.00_echinocyte_III000565.tif\n",
      "Copied: 1.00_echinocyte_III000566.tif\n",
      "Copied: 1.00_echinocyte_III000567.tif\n",
      "Copied: 1.00_echinocyte_III000568.tif\n",
      "Copied: 1.00_echinocyte_III000569.tif\n",
      "Copied: 1.00_echinocyte_III000570.tif\n",
      "Copied: 1.00_echinocyte_III000571.tif\n",
      "Copied: 1.00_echinocyte_III000572.tif\n",
      "Copied: 1.00_echinocyte_III000573.tif\n",
      "Copied: 1.00_echinocyte_III000574.tif\n",
      "Copied: 1.00_echinocyte_III000575.tif\n",
      "Copied: 1.00_echinocyte_III000576.tif\n",
      "Copied: 1.00_echinocyte_III000577.tif\n",
      "Copied: 1.00_echinocyte_III000578.tif\n",
      "Copied: 1.00_echinocyte_III000579.tif\n",
      "Copied: 1.00_echinocyte_III000580.tif\n",
      "Copied: 1.00_echinocyte_III000581.tif\n",
      "Copied: 1.00_echinocyte_III000582.tif\n",
      "Copied: 1.00_echinocyte_III000583.tif\n",
      "Copied: 1.00_echinocyte_III000584.tif\n",
      "Copied: 1.00_echinocyte_III000585.tif\n",
      "Copied: 1.00_echinocyte_III000586.tif\n",
      "Copied: 1.00_echinocyte_III000587.tif\n",
      "Copied: 1.00_echinocyte_III000588.tif\n",
      "Copied: 1.00_echinocyte_III000589.tif\n",
      "Copied: 1.00_echinocyte_III000590.tif\n",
      "Copied: 1.00_echinocyte_III000591.tif\n",
      "Copied: 1.00_echinocyte_III000592.tif\n",
      "Copied: 1.00_echinocyte_III000593.tif\n",
      "Copied: 1.00_echinocyte_III000594.tif\n",
      "Copied: 1.00_echinocyte_III000595.tif\n",
      "Copied: 1.00_echinocyte_III000596.tif\n",
      "Copied: 1.00_echinocyte_III000597.tif\n",
      "Copied: 1.00_echinocyte_III000598.tif\n",
      "Copied: 1.00_echinocyte_III000599.tif\n",
      "Copied: 1.00_echinocyte_III000600.tif\n",
      "Copied: 1.00_echinocyte_III000601.tif\n",
      "Copied: 1.00_echinocyte_III000602.tif\n",
      "Copied: 1.00_echinocyte_III000603.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/echinocyte. Total files copied: 292\n",
      "Copied: B_keratocytes000673.tif\n",
      "Copied: B_keratocytes000674.tif\n",
      "Copied: B_keratocytes000675.tif\n",
      "Copied: B_keratocytes000676.tif\n",
      "Copied: B_keratocytes000677.tif\n",
      "Copied: B_keratocytes000678.tif\n",
      "Copied: B_keratocytes000679.tif\n",
      "Copied: B_keratocytes000680.tif\n",
      "Copied: B_keratocytes000681.tif\n",
      "Copied: B_keratocytes000682.tif\n",
      "Copied: B_keratocytes000683.tif\n",
      "Copied: B_keratocytes000684.tif\n",
      "Copied: B_keratocytes000685.tif\n",
      "Copied: B_keratocytes000686.tif\n",
      "Copied: B_keratocytes000687.tif\n",
      "Copied: B_keratocytes000688.tif\n",
      "Copied: B_keratocytes000689.tif\n",
      "Copied: B_keratocytes000690.tif\n",
      "Copied: B_keratocytes000691.tif\n",
      "Copied: B_keratocytes000692.tif\n",
      "Copied: B_keratocytes000693.tif\n",
      "Copied: B_keratocytes000694.tif\n",
      "Copied: B_keratocytes000695.tif\n",
      "Copied: B_keratocytes000696.tif\n",
      "Copied: B_keratocytes000697.tif\n",
      "Copied: B_keratocytes000698.tif\n",
      "Copied: B_keratocytes000699.tif\n",
      "Copied: B_keratocytes000700.tif\n",
      "Copied: B_keratocytes000701.tif\n",
      "Copied: B_keratocytes000702.tif\n",
      "Copied: B_keratocytes000703.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/keratocytes. Total files copied: 31\n",
      "Copied: D_multilobate_cells000727.tif\n",
      "Copied: D_multilobate_cells000728.tif\n",
      "Copied: D_multilobate_cells000729.tif\n",
      "Copied: D_multilobate_cells000730.tif\n",
      "Copied: D_multilobate_cells000731.tif\n",
      "Copied: D_multilobate_cells000732.tif\n",
      "Copied: D_multilobate_cells000733.tif\n",
      "Copied: D_multilobate_cells000734.tif\n",
      "Copied: D_multilobate_cells000735.tif\n",
      "Copied: D_multilobate_cells000736.tif\n",
      "Copied: D_multilobate_cells000737.tif\n",
      "Copied: D_multilobate_cells000738.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/multilobate_cells. Total files copied: 12\n",
      "Copied: A_cell_clusters000604.tif\n",
      "Copied: A_cell_clusters000605.tif\n",
      "Copied: A_cell_clusters000606.tif\n",
      "Copied: A_cell_clusters000607.tif\n",
      "Copied: A_cell_clusters000608.tif\n",
      "Copied: A_cell_clusters000609.tif\n",
      "Copied: A_cell_clusters000610.tif\n",
      "Copied: A_cell_clusters000611.tif\n",
      "Copied: A_cell_clusters000612.tif\n",
      "Copied: A_cell_clusters000613.tif\n",
      "Copied: A_cell_clusters000614.tif\n",
      "Copied: A_cell_clusters000615.tif\n",
      "Copied: A_cell_clusters000616.tif\n",
      "Copied: A_cell_clusters000617.tif\n",
      "Copied: A_cell_clusters000618.tif\n",
      "Copied: A_cell_clusters000619.tif\n",
      "Copied: A_cell_clusters000620.tif\n",
      "Copied: A_cell_clusters000621.tif\n",
      "Copied: A_cell_clusters000622.tif\n",
      "Copied: A_cell_clusters000623.tif\n",
      "Copied: A_cell_clusters000624.tif\n",
      "Copied: A_cell_clusters000625.tif\n",
      "Copied: A_cell_clusters000626.tif\n",
      "Copied: A_cell_clusters000627.tif\n",
      "Copied: A_cell_clusters000628.tif\n",
      "Copied: A_cell_clusters000629.tif\n",
      "Copied: A_cell_clusters000630.tif\n",
      "Copied: A_cell_clusters000631.tif\n",
      "Copied: A_cell_clusters000632.tif\n",
      "Copied: A_cell_clusters000633.tif\n",
      "Copied: A_cell_clusters000634.tif\n",
      "Copied: A_cell_clusters000635.tif\n",
      "Copied: A_cell_clusters000636.tif\n",
      "Copied: A_cell_clusters000637.tif\n",
      "Copied: A_cell_clusters000638.tif\n",
      "Copied: A_cell_clusters000639.tif\n",
      "Copied: A_cell_clusters000640.tif\n",
      "Copied: A_cell_clusters000641.tif\n",
      "Copied: A_cell_clusters000642.tif\n",
      "Copied: A_cell_clusters000643.tif\n",
      "Copied: A_cell_clusters000644.tif\n",
      "Copied: A_cell_clusters000645.tif\n",
      "Copied: A_cell_clusters000646.tif\n",
      "Copied: A_cell_clusters000647.tif\n",
      "Copied: A_cell_clusters000648.tif\n",
      "Copied: A_cell_clusters000649.tif\n",
      "Copied: A_cell_clusters000650.tif\n",
      "Copied: A_cell_clusters000651.tif\n",
      "Copied: A_cell_clusters000652.tif\n",
      "Copied: A_cell_clusters000653.tif\n",
      "Copied: A_cell_clusters000654.tif\n",
      "Copied: A_cell_clusters000655.tif\n",
      "Copied: A_cell_clusters000656.tif\n",
      "Copied: A_cell_clusters000657.tif\n",
      "Copied: A_cell_clusters000658.tif\n",
      "Copied: A_cell_clusters000659.tif\n",
      "Copied: A_cell_clusters000660.tif\n",
      "Copied: A_cell_clusters000661.tif\n",
      "Copied: A_cell_clusters000662.tif\n",
      "Copied: A_cell_clusters000663.tif\n",
      "Copied: A_cell_clusters000664.tif\n",
      "Copied: A_cell_clusters000665.tif\n",
      "Copied: A_cell_clusters000666.tif\n",
      "Copied: A_cell_clusters000667.tif\n",
      "Copied: A_cell_clusters000668.tif\n",
      "Copied: A_cell_clusters000669.tif\n",
      "Copied: A_cell_clusters000670.tif\n",
      "Copied: A_cell_clusters000671.tif\n",
      "Copied: A_cell_clusters000672.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/cell_clusters. Total files copied: 69\n",
      "Copied: C_knizocytes000704.tif\n",
      "Copied: C_knizocytes000705.tif\n",
      "Copied: C_knizocytes000706.tif\n",
      "Copied: C_knizocytes000707.tif\n",
      "Copied: C_knizocytes000708.tif\n",
      "Copied: C_knizocytes000709.tif\n",
      "Copied: C_knizocytes000710.tif\n",
      "Copied: C_knizocytes000711.tif\n",
      "Copied: C_knizocytes000712.tif\n",
      "Copied: C_knizocytes000713.tif\n",
      "Copied: C_knizocytes000714.tif\n",
      "Copied: C_knizocytes000715.tif\n",
      "Copied: C_knizocytes000716.tif\n",
      "Copied: C_knizocytes000717.tif\n",
      "Copied: C_knizocytes000718.tif\n",
      "Copied: C_knizocytes000719.tif\n",
      "Copied: C_knizocytes000720.tif\n",
      "Copied: C_knizocytes000721.tif\n",
      "Copied: C_knizocytes000722.tif\n",
      "Copied: C_knizocytes000723.tif\n",
      "Copied: C_knizocytes000724.tif\n",
      "Copied: C_knizocytes000725.tif\n",
      "Copied: C_knizocytes000726.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/knizocytes. Total files copied: 23\n",
      "Copied: D_multilobate_cells000727.tif\n",
      "Copied: D_multilobate_cells000728.tif\n",
      "Copied: D_multilobate_cells000729.tif\n",
      "Copied: D_multilobate_cells000730.tif\n",
      "Copied: D_multilobate_cells000731.tif\n",
      "Copied: D_multilobate_cells000732.tif\n",
      "Copied: D_multilobate_cells000733.tif\n",
      "Copied: D_multilobate_cells000734.tif\n",
      "Copied: D_multilobate_cells000735.tif\n",
      "Copied: D_multilobate_cells000736.tif\n",
      "Copied: D_multilobate_cells000737.tif\n",
      "Copied: D_multilobate_cells000738.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/multilobate_cells. Total files copied: 12\n",
      "Copied: E_acanthocytes000739.tif\n",
      "Copied: E_acanthocytes000740.tif\n",
      "Copied: E_acanthocytes000741.tif\n",
      "Copied: E_acanthocytes000742.tif\n",
      "Copied: E_acanthocytes000743.tif\n",
      "Copied: E_acanthocytes000744.tif\n",
      "Copied: E_acanthocytes000745.tif\n",
      "Copied: E_acanthocytes000746.tif\n",
      "Copied: E_acanthocytes000747.tif\n",
      "Copied: E_acanthocytes000748.tif\n",
      "Copied: E_acanthocytes000749.tif\n",
      "Copied: E_acanthocytes000750.tif\n",
      "Copied: E_acanthocytes000751.tif\n",
      "Copied: E_acanthocytes000752.tif\n",
      "Copied: E_acanthocytes000753.tif\n",
      "Copied: E_acanthocytes000754.tif\n",
      "Copied: E_acanthocytes000755.tif\n",
      "Copied: E_acanthocytes000756.tif\n",
      "Copied: E_acanthocytes000757.tif\n",
      "Copied: E_acanthocytes000758.tif\n",
      "Copied: E_acanthocytes000759.tif\n",
      "Copied: E_acanthocytes000760.tif\n",
      "Copied: E_acanthocytes000761.tif\n",
      "Copied: E_acanthocytes000762.tif\n",
      "Copied: E_acanthocytes000763.tif\n",
      "Copied: E_acanthocytes000764.tif\n",
      "Copied: E_acanthocytes000765.tif\n",
      "Copied: E_acanthocytes000766.tif\n",
      "Copied: E_acanthocytes000767.tif\n",
      "Copied: E_acanthocytes000768.tif\n",
      "Copied: E_acanthocytes000769.tif\n",
      "Copied: E_acanthocytes000770.tif\n",
      "Copied: E_acanthocytes000771.tif\n",
      "Copied: E_acanthocytes000772.tif\n",
      "Copied: E_acanthocytes000773.tif\n",
      "Copied: E_acanthocytes000774.tif\n",
      "Copied: E_acanthocytes000775.tif\n",
      "Copied: E_acanthocytes000776.tif\n",
      "Copied: E_acanthocytes000777.tif\n",
      "Copied: E_acanthocytes000778.tif\n",
      "Copied: E_acanthocytes000779.tif\n",
      "Copied: E_acanthocytes000780.tif\n",
      "Copied: E_acanthocytes000781.tif\n",
      "Copied: E_acanthocytes000782.tif\n",
      "Copied: E_acanthocytes000783.tif\n",
      "Copied: E_acanthocytes000784.tif\n",
      "Copied: E_acanthocytes000785.tif\n",
      "Copied: E_acanthocytes000786.tif\n",
      "Copied: E_acanthocytes000787.tif\n",
      "Copied: E_acanthocytes000788.tif\n",
      "Copied: E_acanthocytes000789.tif\n",
      "Copied: E_acanthocytes000790.tif\n",
      "Copied: E_acanthocytes000791.tif\n",
      "Copied: E_acanthocytes000792.tif\n",
      "Copied: E_acanthocytes000793.tif\n",
      "Copied: E_acanthocytes000794.tif\n",
      "Copied: E_acanthocytes000795.tif\n",
      "Copied: E_acanthocytes000796.tif\n",
      "Copied: E_acanthocytes000797.tif\n",
      "Copied: E_acanthocytes000798.tif\n",
      "Copied: E_acanthocytes000799.tif\n",
      "Copied: E_acanthocytes000800.tif\n",
      "Copied: E_acanthocytes000801.tif\n",
      "Copied: E_acanthocytes000802.tif\n",
      "Copied: E_acanthocytes000803.tif\n",
      "Copied: E_acanthocytes000804.tif\n",
      "Copied: E_acanthocytes000805.tif\n",
      "Copied: E_acanthocytes000806.tif\n",
      "Copied: E_acanthocytes000807.tif\n",
      "Copied: E_acanthocytes000808.tif\n",
      "Copied: E_acanthocytes000809.tif\n",
      "Copied: E_acanthocytes000810.tif\n",
      "Copied: E_acanthocytes000811.tif\n",
      "Copied: E_acanthocytes000812.tif\n",
      "Copied: E_acanthocytes000813.tif\n",
      "Copied: E_acanthocytes000814.tif\n",
      "Copied: E_acanthocytes000815.tif\n",
      "Copied: E_acanthocytes000816.tif\n",
      "Copied: E_acanthocytes000817.tif\n",
      "Copied: E_acanthocytes000818.tif\n",
      "Copied: E_acanthocytes000819.tif\n",
      "Copied: E_acanthocytes000820.tif\n",
      "Copied: E_acanthocytes000821.tif\n",
      "Copied: E_acanthocytes000822.tif\n",
      "Copied: E_acanthocytes000823.tif\n",
      "Copied: E_acanthocytes000824.tif\n",
      "Copied: E_acanthocytes000825.tif\n",
      "Copied: E_acanthocytes000826.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/acanthocytes. Total files copied: 88\n",
      "Copied: -0.33_stomatocyte_I000000.tif\n",
      "Copied: -0.33_stomatocyte_I000001.tif\n",
      "Copied: -0.33_stomatocyte_I000002.tif\n",
      "Copied: -0.33_stomatocyte_I000003.tif\n",
      "Copied: -0.33_stomatocyte_I000004.tif\n",
      "Copied: -0.33_stomatocyte_I000005.tif\n",
      "Copied: -0.33_stomatocyte_I000006.tif\n",
      "Copied: -0.33_stomatocyte_I000007.tif\n",
      "Copied: -0.33_stomatocyte_I000008.tif\n",
      "Copied: -0.33_stomatocyte_I000009.tif\n",
      "Copied: -0.33_stomatocyte_I000010.tif\n",
      "Copied: -0.33_stomatocyte_I000011.tif\n",
      "Copied: -0.33_stomatocyte_I000012.tif\n",
      "Copied: -0.33_stomatocyte_I000013.tif\n",
      "Copied: -0.33_stomatocyte_I000014.tif\n",
      "Copied: -0.33_stomatocyte_I000015.tif\n",
      "Copied: -0.33_stomatocyte_I000016.tif\n",
      "Copied: -0.33_stomatocyte_I000017.tif\n",
      "Copied: -0.33_stomatocyte_I000018.tif\n",
      "Copied: -0.33_stomatocyte_I000019.tif\n",
      "Copied: -0.33_stomatocyte_I000020.tif\n",
      "Copied: -0.33_stomatocyte_I000021.tif\n",
      "Copied: -0.33_stomatocyte_I000022.tif\n",
      "Copied: -0.33_stomatocyte_I000023.tif\n",
      "Copied: -0.33_stomatocyte_I000024.tif\n",
      "Copied: -0.33_stomatocyte_I000025.tif\n",
      "Copied: -0.33_stomatocyte_I000026.tif\n",
      "Copied: -0.33_stomatocyte_I000027.tif\n",
      "Copied: -0.33_stomatocyte_I000028.tif\n",
      "Copied: -0.33_stomatocyte_I000029.tif\n",
      "Copied: -0.67_stomatocyte_II000030.tif\n",
      "Copied: -0.67_stomatocyte_II000031.tif\n",
      "Copied: -0.67_stomatocyte_II000032.tif\n",
      "Copied: -0.67_stomatocyte_II000033.tif\n",
      "Copied: -0.67_stomatocyte_II000034.tif\n",
      "Copied: -0.67_stomatocyte_II000035.tif\n",
      "Copied: -0.67_stomatocyte_II000036.tif\n",
      "Copied: -0.67_stomatocyte_II000037.tif\n",
      "Copied: -0.67_stomatocyte_II000038.tif\n",
      "Copied: -0.67_stomatocyte_II000039.tif\n",
      "Copied: -0.67_stomatocyte_II000042.tif\n",
      "All matching files have been copied to /Volumes/TOSHIBA EXT/Projects/Datasets/dataset_for_3D_reconstruction/image/stomatocyte. Total files copied: 41\n"
     ]
    }
   ],
   "source": [
    "for cell_type in cell_types:\n",
    "    directory_path = image_path\n",
    "    destination_path = image_path + '/' + cell_type\n",
    "    regex_pattern = rf'.*{cell_type}.*\\.tif$'\n",
    "\n",
    "    copy_files_by_pattern(directory_path, destination_path, regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/compvision/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "class Patches(Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.pos_embed = Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_proj = Dense(self.projection_dim, use_bias=False)\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        x = self.dense_proj(patch) + self.pos_embed(positions)\n",
    "        return x\n",
    "\n",
    "def transformer_block(x, projection_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "    # Multi-head self-attention\n",
    "    attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=projection_dim, dropout=dropout)(x, x)\n",
    "    # Skip connection 1\n",
    "    x = tf.keras.layers.Add()([attention_output, x])\n",
    "    # LayerNorm 1\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    # MLP\n",
    "    x_intermediate = tf.keras.layers.Dense(mlp_dim, activation=tf.nn.gelu)(x)\n",
    "    x_output = tf.keras.layers.Dense(projection_dim)(x_intermediate)\n",
    "    # Skip connection 2\n",
    "    x = tf.keras.layers.Add()([x_output, x])\n",
    "    # LayerNorm 2\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vit_classifier(num_classes, image_size=64, patch_size=8, projection_dim=128, num_heads=8, transformer_layers=6, mlp_dim=256):\n",
    "    inputs = tf.keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    num_patches = (image_size // patch_size) ** 2\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    x = encoded_patches\n",
    "    for _ in range(transformer_layers):\n",
    "        x = transformer_block(x, projection_dim, num_heads, mlp_dim, dropout=0.1)\n",
    "\n",
    "    # Classifier head\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(mlp_dim, activation='relu')(x)  # First Dense layer\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(mlp_dim // 2, activation='relu')(x)  # Second Dense layer\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 523 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 126 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set paths to your data directories\n",
    "\n",
    "data_dir = image_path+'/Class'\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,    # Normalize pixel values\n",
    "    validation_split=0.2  # Reserve 20% for validation\n",
    ")\n",
    "\n",
    "# Setup the train generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(64, 64),  # Load images at 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',  # Ensure this matches the loss function\n",
    "    subset='training',  # Set as training data\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Setup the validation generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(64, 64),  # Load images at 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',  # Ensure this matches the loss function\n",
    "    subset='validation',  # Set as validation data\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/compvision/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.2485 - loss: 2.2738 - val_accuracy: 0.4603 - val_loss: 1.6888\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3985 - loss: 1.9180 - val_accuracy: 0.4603 - val_loss: 1.6792\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.4210 - loss: 1.8101 - val_accuracy: 0.4603 - val_loss: 1.6614\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.4559 - loss: 1.6929 - val_accuracy: 0.4603 - val_loss: 1.6816\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.4070 - loss: 1.7855 - val_accuracy: 0.4603 - val_loss: 1.6553\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.4229 - loss: 1.7830 - val_accuracy: 0.4603 - val_loss: 1.6850\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = build_vit_classifier(num_classes=8)  # Assuming 8 classes\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early Stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,  # You can set a higher epoch if early stopping is used\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 07m 13s]\n",
      "val_accuracy: 0.5952380895614624\n",
      "\n",
      "Best val_accuracy So Far: 0.5952380895614624\n",
      "Total elapsed time: 00h 53m 38s\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras-tuner\n",
    "from kerastuner import RandomSearch\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    num_layers = hp.Int('num_layers', min_value=2, max_value=6, step=1)\n",
    "    num_heads = hp.Int('num_heads', min_value=4, max_value=12, step=2)\n",
    "    d_model = hp.Int('d_model', min_value=64, max_value=256, step=64)\n",
    "    mlp_dim = hp.Int('mlp_dim', min_value=128, max_value=512, step=64)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    model = build_vit_classifier(\n",
    "        num_classes=8, \n",
    "        image_size=64, \n",
    "        patch_size=8, \n",
    "        projection_dim=d_model, \n",
    "        num_heads=num_heads, \n",
    "        transformer_layers=num_layers, \n",
    "        mlp_dim=mlp_dim\n",
    "    )\n",
    "    lr = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of variations\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='hparam_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(train_generator, epochs=10, validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'Int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming `build_model` is a function that can take the hyperparameters from\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# the build configuration and return a compiled Keras model:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m hp \u001b[38;5;241m=\u001b[39m build_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# this may vary depending on the exact structure of your build_config.json\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Now load the weights\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(model_path)\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(hp):\n\u001b[0;32m----> 6\u001b[0m     num_layers \u001b[38;5;241m=\u001b[39m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInt\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m, min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     num_heads \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mInt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_heads\u001b[39m\u001b[38;5;124m'\u001b[39m, min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m     d_model \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mInt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m'\u001b[39m, min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'Int'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "model_path='/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/checkpoint.weights.h5'\n",
    "\n",
    "# Reconstruct the model from the saved build configuration\n",
    "with open('/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/trial.json', 'r') as json_file:\n",
    "    build_config = json.load(json_file)\n",
    "\n",
    "# Assuming `build_model` is a function that can take the hyperparameters from\n",
    "# the build configuration and return a compiled Keras model:\n",
    "hp = build_config['hyperparameters']  # this may vary depending on the exact structure of your build_config.json\n",
    "model = build_model(hp)\n",
    "\n",
    "# Now load the weights\n",
    "model.load_weights(model_path)\n",
    "\n",
    "# You can now use model to evaluate, make predictions, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model config found in the file at /Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/checkpoint.weights.h5.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/checkpoint.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use the model for predictions\u001b[39;00m\n\u001b[1;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(validation_generator)\n",
      "File \u001b[0;32m~/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/compvision/lib/python3.9/site-packages/keras/src/saving/saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    177\u001b[0m         filepath,\n\u001b[1;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/compvision/lib/python3.9/site-packages/keras/src/legacy/saving/legacy_h5_format.py:125\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    123\u001b[0m model_config \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model config found in the file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    129\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No model config found in the file at /Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/checkpoint.weights.h5."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path='/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/checkpoint.weights.h5'\n",
    "# Load the model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Use the model for predictions\n",
    "predictions = model.predict(validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/compvision/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 178 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming the build_vit_classifier function is defined elsewhere and it is designed\n",
    "# to build the model according to the given hyperparameters\n",
    "model = build_vit_classifier(\n",
    "    num_classes=8,  # Number of classes\n",
    "    image_size=64,  # Image size\n",
    "    patch_size=8,  # Patch size\n",
    "    projection_dim=192,  # d_model equivalent from JSON\n",
    "    num_heads=10,  # num_heads from JSON\n",
    "    transformer_layers=5,  # num_layers from JSON\n",
    "    mlp_dim=384  # mlp_dim from JSON\n",
    ")\n",
    "\n",
    "# Set the learning rate as found in the JSON\n",
    "learning_rate = 7.662902023326896e-05\n",
    "\n",
    "# Compile the model with the optimizer and learning rate from the hyperparameters\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_path='/Users/kanumadhok/Desktop/Desktop Kanu/UChicago/Class/AdvancedComputerVisionDeepLearning/Final Project/AdvancedCompVisionProject/my_dir/hparam_tuning/trial_09/checkpoint.weights.h5'\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights(model_path)\n",
    "\n",
    "# Now, the model is ready to be used for evaluation or further training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.6058 - loss: 1.4137\n",
      "Validation accuracy: 59.52%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 901ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1622264 , 0.10125488, 0.24668248, ..., 0.07036846, 0.19767684,\n",
       "        0.07806119],\n",
       "       [0.32759884, 0.06651262, 0.19850148, ..., 0.06150077, 0.1627068 ,\n",
       "        0.04101174],\n",
       "       [0.10981067, 0.11962286, 0.37509245, ..., 0.05189702, 0.13290685,\n",
       "        0.0852427 ],\n",
       "       ...,\n",
       "       [0.04098357, 0.15492082, 0.60078555, ..., 0.02791126, 0.03793916,\n",
       "        0.08649072],\n",
       "       [0.0150673 , 0.1623144 , 0.71190464, ..., 0.01710396, 0.01143766,\n",
       "        0.06273289],\n",
       "       [0.11631525, 0.10929331, 0.41672182, ..., 0.04564495, 0.11654524,\n",
       "        0.07627453]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(validation_generator)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 2, 2, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 6, 2, 6, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2, 2, 2, 2,\n",
       "       2, 6, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 6, 2, 2, 2,\n",
       "       2, 6, 2, 6, 2, 2, 2, 0, 2, 2, 2, 2, 2, 6, 2, 2, 2, 0, 6, 6, 2, 6,\n",
       "       2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_predictions = np.argmax(predictions, axis=1)\n",
    "class_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2145 - loss: 2.2477\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46032, saving model to best_model_vit_addedcomplex.keras\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 7s/step - accuracy: 0.2175 - loss: 2.2415 - val_accuracy: 0.4603 - val_loss: 1.7265\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2611 - loss: 1.9924\n",
      "Epoch 2: val_accuracy did not improve from 0.46032\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 7s/step - accuracy: 0.2645 - loss: 1.9899 - val_accuracy: 0.4603 - val_loss: 1.6468\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3463 - loss: 1.8769\n",
      "Epoch 3: val_accuracy did not improve from 0.46032\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 7s/step - accuracy: 0.3474 - loss: 1.8760 - val_accuracy: 0.4603 - val_loss: 1.6406\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.3721 - loss: 1.8315\n",
      "Epoch 4: val_accuracy did not improve from 0.46032\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8s/step - accuracy: 0.3734 - loss: 1.8285 - val_accuracy: 0.4603 - val_loss: 1.6275\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Assuming the build_vit_classifier function is defined elsewhere and it is designed\n",
    "# to build the model according to the given hyperparameters\n",
    "# Rebuild the model with the same hyperparameters that gave the best results\n",
    "# but with increased complexity\n",
    "model = build_vit_classifier(\n",
    "    num_classes=8,\n",
    "    image_size=64,\n",
    "    patch_size=8,\n",
    "    projection_dim=250,  # Consider increasing this value\n",
    "    num_heads=10,\n",
    "    transformer_layers=10,  # Consider adding more layers\n",
    "    mlp_dim=450  # Consider increasing this value\n",
    ")\n",
    "\n",
    "\n",
    "# Set the learning rate as found in the JSON\n",
    "learning_rate = 7.662902023326896e-05\n",
    "\n",
    "# Compile the model with the optimizer and learning rate from the hyperparameters\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Set up model checkpointing\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_vit_addedcomplex.keras',  # Path where to save the model\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "\n",
    "# Continue training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # More epochs than before\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

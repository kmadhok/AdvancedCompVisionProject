{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (2.0.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.14.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/fc/a5/4d82be566f069d7a9a702dcdf6f9106df0e0b042e738043c0cc7ddd7e3f6/pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m144.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m130.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install keras-tuner\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: -1.00_spherocyte000129.tif\n",
      "Copied: -1.00_spherocyte000130.tif\n",
      "Copied: -1.00_spherocyte000116.tif\n",
      "Copied: -1.00_spherocyte000113.tif\n",
      "Copied: -1.00_spherocyte000134.tif\n",
      "Copied: -1.00_spherocyte000132.tif\n",
      "Copied: -1.00_spherocyte000127.tif\n",
      "Copied: -1.00_spherocyte000118.tif\n",
      "Copied: -1.00_spherocyte000133.tif\n",
      "Copied: -1.00_spherocyte000135.tif\n",
      "Copied: -1.00_spherocyte000122.tif\n",
      "Copied: -1.00_spherocyte000131.tif\n",
      "Copied: -1.00_spherocyte000128.tif\n",
      "Copied: -1.00_spherocyte000124.tif\n",
      "Copied: -1.00_spherocyte000125.tif\n",
      "Copied: -1.00_spherocyte000126.tif\n",
      "Copied: -1.00_spherocyte000123.tif\n",
      "Copied: -1.00_spherocyte000121.tif\n",
      "Copied: -1.00_spherocyte000120.tif\n",
      "Copied: -1.00_spherocyte000119.tif\n",
      "Copied: -1.00_spherocyte000117.tif\n",
      "Copied: -1.00_spherocyte000112.tif\n",
      "Copied: -1.00_spherocyte000114.tif\n",
      "Copied: -1.00_spherocyte000115.tif\n",
      "Copied: -1.00_spherocyte000110.tif\n",
      "Copied: -1.00_spherocyte000109.tif\n",
      "Copied: -1.00_spherocyte000075.tif\n",
      "Copied: -1.00_spherocyte000052.tif\n",
      "Copied: -1.00_spherocyte000056.tif\n",
      "Copied: -1.00_spherocyte000069.tif\n",
      "Copied: -1.00_spherocyte000054.tif\n",
      "Copied: -1.00_spherocyte000076.tif\n",
      "Copied: -1.00_spherocyte000068.tif\n",
      "Copied: -1.00_spherocyte000062.tif\n",
      "Copied: -1.00_spherocyte000083.tif\n",
      "Copied: -1.00_spherocyte000060.tif\n",
      "Copied: -1.00_spherocyte000100.tif\n",
      "Copied: -1.00_spherocyte000108.tif\n",
      "Copied: -1.00_spherocyte000107.tif\n",
      "Copied: -1.00_spherocyte000111.tif\n",
      "Copied: -1.00_spherocyte000094.tif\n",
      "Copied: -1.00_spherocyte000104.tif\n",
      "Copied: -1.00_spherocyte000089.tif\n",
      "Copied: -1.00_spherocyte000106.tif\n",
      "Copied: -1.00_spherocyte000090.tif\n",
      "Copied: -1.00_spherocyte000105.tif\n",
      "Copied: -1.00_spherocyte000103.tif\n",
      "Copied: -1.00_spherocyte000093.tif\n",
      "Copied: -1.00_spherocyte000088.tif\n",
      "Copied: -1.00_spherocyte000091.tif\n",
      "Copied: -1.00_spherocyte000101.tif\n",
      "Copied: -1.00_spherocyte000086.tif\n",
      "Copied: -1.00_spherocyte000097.tif\n",
      "Copied: -1.00_spherocyte000092.tif\n",
      "Copied: -1.00_spherocyte000063.tif\n",
      "Copied: -1.00_spherocyte000049.tif\n",
      "Copied: -1.00_spherocyte000084.tif\n",
      "Copied: -1.00_spherocyte000095.tif\n",
      "Copied: -1.00_spherocyte000098.tif\n",
      "Copied: -1.00_spherocyte000085.tif\n",
      "Copied: -1.00_spherocyte000096.tif\n",
      "Copied: -1.00_spherocyte000078.tif\n",
      "Copied: -1.00_spherocyte000058.tif\n",
      "Copied: -1.00_spherocyte000055.tif\n",
      "Copied: -1.00_spherocyte000051.tif\n",
      "Copied: -1.00_spherocyte000047.tif\n",
      "Copied: -1.00_spherocyte000053.tif\n",
      "Copied: -1.00_spherocyte000099.tif\n",
      "Copied: -1.00_spherocyte000071.tif\n",
      "Copied: -1.00_spherocyte000044.tif\n",
      "Copied: -1.00_spherocyte000043.tif\n",
      "Copied: -1.00_spherocyte000061.tif\n",
      "Copied: -1.00_spherocyte000087.tif\n",
      "Copied: -1.00_spherocyte000070.tif\n",
      "Copied: -1.00_spherocyte000080.tif\n",
      "Copied: -1.00_spherocyte000064.tif\n",
      "Copied: -1.00_spherocyte000059.tif\n",
      "Copied: -1.00_spherocyte000077.tif\n",
      "Copied: -1.00_spherocyte000082.tif\n",
      "Copied: -1.00_spherocyte000065.tif\n",
      "Copied: -1.00_spherocyte000072.tif\n",
      "Copied: -1.00_spherocyte000081.tif\n",
      "Copied: -1.00_spherocyte000045.tif\n",
      "Copied: -1.00_spherocyte000067.tif\n",
      "Copied: -1.00_spherocyte000057.tif\n",
      "Copied: -1.00_spherocyte000073.tif\n",
      "Copied: -1.00_spherocyte000079.tif\n",
      "Copied: -1.00_spherocyte000050.tif\n",
      "Copied: -1.00_spherocyte000074.tif\n",
      "Copied: -1.00_spherocyte000066.tif\n",
      "Copied: -1.00_spherocyte000046.tif\n",
      "Copied: -1.00_spherocyte000048.tif\n",
      "Copied: -1.00_spherocyte000102.tif\n",
      "All matching files have been copied to image/spherocyte. Total files copied: 93\n",
      "Copied: 0.33_echinocyte_I000320.tif\n",
      "Copied: 0.67_echinocyte_II000366.tif\n",
      "Copied: 1.00_echinocyte_III000543.tif\n",
      "Copied: 1.00_echinocyte_III000493.tif\n",
      "Copied: 0.67_echinocyte_II000435.tif\n",
      "Copied: 0.67_echinocyte_II000414.tif\n",
      "Copied: 1.00_echinocyte_III000515.tif\n",
      "Copied: 0.33_echinocyte_I000326.tif\n",
      "Copied: 1.00_echinocyte_III000570.tif\n",
      "Copied: 1.00_echinocyte_III000592.tif\n",
      "Copied: 1.00_echinocyte_III000583.tif\n",
      "Copied: 1.00_echinocyte_III000558.tif\n",
      "Copied: 1.00_echinocyte_III000553.tif\n",
      "Copied: 1.00_echinocyte_III000552.tif\n",
      "Copied: 1.00_echinocyte_III000551.tif\n",
      "Copied: 1.00_echinocyte_III000550.tif\n",
      "Copied: 1.00_echinocyte_III000549.tif\n",
      "Copied: 1.00_echinocyte_III000508.tif\n",
      "Copied: 0.67_echinocyte_II000429.tif\n",
      "Copied: 0.67_echinocyte_II000411.tif\n",
      "Copied: 1.00_echinocyte_III000495.tif\n",
      "Copied: 0.67_echinocyte_II000406.tif\n",
      "Copied: 0.67_echinocyte_II000420.tif\n",
      "Copied: 1.00_echinocyte_III000490.tif\n",
      "Copied: 1.00_echinocyte_III000438.tif\n",
      "Copied: 0.33_echinocyte_I000332.tif\n",
      "Copied: 0.33_echinocyte_I000333.tif\n",
      "Copied: 0.33_echinocyte_I000316.tif\n",
      "Copied: 1.00_echinocyte_III000455.tif\n",
      "Copied: 1.00_echinocyte_III000548.tif\n",
      "Copied: 0.67_echinocyte_II000398.tif\n",
      "Copied: 1.00_echinocyte_III000443.tif\n",
      "Copied: 0.67_echinocyte_II000394.tif\n",
      "Copied: 0.67_echinocyte_II000396.tif\n",
      "Copied: 0.67_echinocyte_II000384.tif\n",
      "Copied: 0.67_echinocyte_II000376.tif\n",
      "Copied: 1.00_echinocyte_III000439.tif\n",
      "Copied: 0.33_echinocyte_I000338.tif\n",
      "Copied: 0.33_echinocyte_I000330.tif\n",
      "Copied: 0.67_echinocyte_II000410.tif\n",
      "Copied: 0.33_echinocyte_I000321.tif\n",
      "Copied: 0.33_echinocyte_I000317.tif\n",
      "Copied: 0.67_echinocyte_II000425.tif\n",
      "Copied: 0.33_echinocyte_I000315.tif\n",
      "Copied: 0.33_echinocyte_I000312.tif\n",
      "Copied: 0.67_echinocyte_II000393.tif\n",
      "Copied: 0.33_echinocyte_I000355.tif\n",
      "Copied: 0.67_echinocyte_II000367.tif\n",
      "Copied: 0.33_echinocyte_I000319.tif\n",
      "Copied: 0.33_echinocyte_I000318.tif\n",
      "Copied: 0.33_echinocyte_I000328.tif\n",
      "Copied: 0.33_echinocyte_I000314.tif\n",
      "Copied: 1.00_echinocyte_III000603.tif\n",
      "Copied: 1.00_echinocyte_III000597.tif\n",
      "Copied: 1.00_echinocyte_III000596.tif\n",
      "Copied: 1.00_echinocyte_III000595.tif\n",
      "Copied: 1.00_echinocyte_III000593.tif\n",
      "Copied: 1.00_echinocyte_III000590.tif\n",
      "Copied: 1.00_echinocyte_III000602.tif\n",
      "Copied: 1.00_echinocyte_III000601.tif\n",
      "Copied: 1.00_echinocyte_III000598.tif\n",
      "Copied: 1.00_echinocyte_III000600.tif\n",
      "Copied: 1.00_echinocyte_III000599.tif\n",
      "Copied: 1.00_echinocyte_III000594.tif\n",
      "Copied: 1.00_echinocyte_III000589.tif\n",
      "Copied: 1.00_echinocyte_III000591.tif\n",
      "Copied: 1.00_echinocyte_III000586.tif\n",
      "Copied: 1.00_echinocyte_III000587.tif\n",
      "Copied: 1.00_echinocyte_III000585.tif\n",
      "Copied: 1.00_echinocyte_III000581.tif\n",
      "Copied: 1.00_echinocyte_III000582.tif\n",
      "Copied: 1.00_echinocyte_III000580.tif\n",
      "Copied: 1.00_echinocyte_III000584.tif\n",
      "Copied: 1.00_echinocyte_III000588.tif\n",
      "Copied: 1.00_echinocyte_III000578.tif\n",
      "Copied: 1.00_echinocyte_III000571.tif\n",
      "Copied: 1.00_echinocyte_III000579.tif\n",
      "Copied: 1.00_echinocyte_III000567.tif\n",
      "Copied: 1.00_echinocyte_III000569.tif\n",
      "Copied: 1.00_echinocyte_III000568.tif\n",
      "Copied: 1.00_echinocyte_III000576.tif\n",
      "Copied: 1.00_echinocyte_III000575.tif\n",
      "Copied: 1.00_echinocyte_III000566.tif\n",
      "Copied: 1.00_echinocyte_III000574.tif\n",
      "Copied: 1.00_echinocyte_III000577.tif\n",
      "Copied: 1.00_echinocyte_III000572.tif\n",
      "Copied: 1.00_echinocyte_III000561.tif\n",
      "Copied: 1.00_echinocyte_III000557.tif\n",
      "Copied: 1.00_echinocyte_III000544.tif\n",
      "Copied: 1.00_echinocyte_III000545.tif\n",
      "Copied: 1.00_echinocyte_III000565.tif\n",
      "Copied: 1.00_echinocyte_III000541.tif\n",
      "Copied: 1.00_echinocyte_III000564.tif\n",
      "Copied: 1.00_echinocyte_III000573.tif\n",
      "Copied: 1.00_echinocyte_III000560.tif\n",
      "Copied: 1.00_echinocyte_III000542.tif\n",
      "Copied: 1.00_echinocyte_III000546.tif\n",
      "Copied: 1.00_echinocyte_III000563.tif\n",
      "Copied: 1.00_echinocyte_III000562.tif\n",
      "Copied: 1.00_echinocyte_III000528.tif\n",
      "Copied: 1.00_echinocyte_III000540.tif\n",
      "Copied: 1.00_echinocyte_III000538.tif\n",
      "Copied: 1.00_echinocyte_III000556.tif\n",
      "Copied: 1.00_echinocyte_III000555.tif\n",
      "Copied: 1.00_echinocyte_III000536.tif\n",
      "Copied: 1.00_echinocyte_III000559.tif\n",
      "Copied: 1.00_echinocyte_III000547.tif\n",
      "Copied: 1.00_echinocyte_III000524.tif\n",
      "Copied: 1.00_echinocyte_III000525.tif\n",
      "Copied: 1.00_echinocyte_III000522.tif\n",
      "Copied: 1.00_echinocyte_III000519.tif\n",
      "Copied: 1.00_echinocyte_III000514.tif\n",
      "Copied: 1.00_echinocyte_III000516.tif\n",
      "Copied: 1.00_echinocyte_III000517.tif\n",
      "Copied: 1.00_echinocyte_III000520.tif\n",
      "Copied: 1.00_echinocyte_III000507.tif\n",
      "Copied: 1.00_echinocyte_III000504.tif\n",
      "Copied: 1.00_echinocyte_III000506.tif\n",
      "Copied: 1.00_echinocyte_III000501.tif\n",
      "Copied: 1.00_echinocyte_III000505.tif\n",
      "Copied: 1.00_echinocyte_III000500.tif\n",
      "Copied: 1.00_echinocyte_III000535.tif\n",
      "Copied: 1.00_echinocyte_III000554.tif\n",
      "Copied: 1.00_echinocyte_III000534.tif\n",
      "Copied: 1.00_echinocyte_III000531.tif\n",
      "Copied: 1.00_echinocyte_III000532.tif\n",
      "Copied: 1.00_echinocyte_III000533.tif\n",
      "Copied: 1.00_echinocyte_III000537.tif\n",
      "Copied: 1.00_echinocyte_III000539.tif\n",
      "Copied: 1.00_echinocyte_III000526.tif\n",
      "Copied: 1.00_echinocyte_III000529.tif\n",
      "Copied: 1.00_echinocyte_III000530.tif\n",
      "Copied: 1.00_echinocyte_III000527.tif\n",
      "Copied: 1.00_echinocyte_III000523.tif\n",
      "Copied: 1.00_echinocyte_III000521.tif\n",
      "Copied: 1.00_echinocyte_III000513.tif\n",
      "Copied: 1.00_echinocyte_III000499.tif\n",
      "Copied: 1.00_echinocyte_III000503.tif\n",
      "Copied: 1.00_echinocyte_III000518.tif\n",
      "Copied: 1.00_echinocyte_III000489.tif\n",
      "Copied: 1.00_echinocyte_III000491.tif\n",
      "Copied: 1.00_echinocyte_III000512.tif\n",
      "Copied: 1.00_echinocyte_III000496.tif\n",
      "Copied: 1.00_echinocyte_III000511.tif\n",
      "Copied: 1.00_echinocyte_III000492.tif\n",
      "Copied: 1.00_echinocyte_III000498.tif\n",
      "Copied: 1.00_echinocyte_III000494.tif\n",
      "Copied: 1.00_echinocyte_III000488.tif\n",
      "Copied: 1.00_echinocyte_III000485.tif\n",
      "Copied: 1.00_echinocyte_III000476.tif\n",
      "Copied: 1.00_echinocyte_III000477.tif\n",
      "Copied: 1.00_echinocyte_III000484.tif\n",
      "Copied: 1.00_echinocyte_III000473.tif\n",
      "Copied: 1.00_echinocyte_III000460.tif\n",
      "Copied: 1.00_echinocyte_III000461.tif\n",
      "Copied: 1.00_echinocyte_III000466.tif\n",
      "Copied: 1.00_echinocyte_III000464.tif\n",
      "Copied: 1.00_echinocyte_III000457.tif\n",
      "Copied: 1.00_echinocyte_III000509.tif\n",
      "Copied: 1.00_echinocyte_III000487.tif\n",
      "Copied: 1.00_echinocyte_III000502.tif\n",
      "Copied: 1.00_echinocyte_III000510.tif\n",
      "Copied: 1.00_echinocyte_III000486.tif\n",
      "Copied: 1.00_echinocyte_III000482.tif\n",
      "Copied: 1.00_echinocyte_III000497.tif\n",
      "Copied: 1.00_echinocyte_III000478.tif\n",
      "Copied: 1.00_echinocyte_III000480.tif\n",
      "Copied: 1.00_echinocyte_III000481.tif\n",
      "Copied: 1.00_echinocyte_III000474.tif\n",
      "Copied: 1.00_echinocyte_III000465.tif\n",
      "Copied: 1.00_echinocyte_III000479.tif\n",
      "Copied: 1.00_echinocyte_III000475.tif\n",
      "Copied: 1.00_echinocyte_III000467.tif\n",
      "Copied: 1.00_echinocyte_III000483.tif\n",
      "Copied: 1.00_echinocyte_III000463.tif\n",
      "Copied: 1.00_echinocyte_III000459.tif\n",
      "Copied: 1.00_echinocyte_III000470.tif\n",
      "Copied: 1.00_echinocyte_III000472.tif\n",
      "Copied: 0.67_echinocyte_II000426.tif\n",
      "Copied: 1.00_echinocyte_III000471.tif\n",
      "Copied: 1.00_echinocyte_III000469.tif\n",
      "Copied: 1.00_echinocyte_III000468.tif\n",
      "Copied: 1.00_echinocyte_III000453.tif\n",
      "Copied: 1.00_echinocyte_III000462.tif\n",
      "Copied: 1.00_echinocyte_III000458.tif\n",
      "Copied: 1.00_echinocyte_III000450.tif\n",
      "Copied: 1.00_echinocyte_III000456.tif\n",
      "Copied: 1.00_echinocyte_III000454.tif\n",
      "Copied: 1.00_echinocyte_III000452.tif\n",
      "Copied: 1.00_echinocyte_III000446.tif\n",
      "Copied: 1.00_echinocyte_III000447.tif\n",
      "Copied: 1.00_echinocyte_III000440.tif\n",
      "Copied: 1.00_echinocyte_III000449.tif\n",
      "Copied: 0.67_echinocyte_II000434.tif\n",
      "Copied: 1.00_echinocyte_III000448.tif\n",
      "Copied: 1.00_echinocyte_III000451.tif\n",
      "Copied: 0.67_echinocyte_II000433.tif\n",
      "Copied: 0.67_echinocyte_II000432.tif\n",
      "Copied: 1.00_echinocyte_III000442.tif\n",
      "Copied: 0.67_echinocyte_II000428.tif\n",
      "Copied: 0.67_echinocyte_II000415.tif\n",
      "Copied: 0.67_echinocyte_II000423.tif\n",
      "Copied: 1.00_echinocyte_III000444.tif\n",
      "Copied: 0.67_echinocyte_II000417.tif\n",
      "Copied: 1.00_echinocyte_III000436.tif\n",
      "Copied: 0.67_echinocyte_II000430.tif\n",
      "Copied: 0.67_echinocyte_II000413.tif\n",
      "Copied: 0.67_echinocyte_II000412.tif\n",
      "Copied: 0.67_echinocyte_II000409.tif\n",
      "Copied: 1.00_echinocyte_III000441.tif\n",
      "Copied: 0.67_echinocyte_II000431.tif\n",
      "Copied: 0.67_echinocyte_II000418.tif\n",
      "Copied: 1.00_echinocyte_III000445.tif\n",
      "Copied: 0.67_echinocyte_II000419.tif\n",
      "Copied: 1.00_echinocyte_III000437.tif\n",
      "Copied: 0.67_echinocyte_II000422.tif\n",
      "Copied: 0.67_echinocyte_II000416.tif\n",
      "Copied: 0.67_echinocyte_II000373.tif\n",
      "Copied: 0.67_echinocyte_II000407.tif\n",
      "Copied: 0.67_echinocyte_II000408.tif\n",
      "Copied: 0.67_echinocyte_II000404.tif\n",
      "Copied: 0.67_echinocyte_II000390.tif\n",
      "Copied: 0.67_echinocyte_II000427.tif\n",
      "Copied: 0.67_echinocyte_II000424.tif\n",
      "Copied: 0.67_echinocyte_II000399.tif\n",
      "Copied: 0.67_echinocyte_II000402.tif\n",
      "Copied: 0.67_echinocyte_II000401.tif\n",
      "Copied: 0.67_echinocyte_II000397.tif\n",
      "Copied: 0.67_echinocyte_II000403.tif\n",
      "Copied: 0.67_echinocyte_II000383.tif\n",
      "Copied: 0.67_echinocyte_II000385.tif\n",
      "Copied: 0.67_echinocyte_II000389.tif\n",
      "Copied: 0.67_echinocyte_II000387.tif\n",
      "Copied: 0.67_echinocyte_II000381.tif\n",
      "Copied: 0.67_echinocyte_II000372.tif\n",
      "Copied: 0.67_echinocyte_II000379.tif\n",
      "Copied: 0.67_echinocyte_II000421.tif\n",
      "Copied: 0.67_echinocyte_II000395.tif\n",
      "Copied: 0.67_echinocyte_II000391.tif\n",
      "Copied: 0.67_echinocyte_II000405.tif\n",
      "Copied: 0.67_echinocyte_II000400.tif\n",
      "Copied: 0.67_echinocyte_II000388.tif\n",
      "Copied: 0.67_echinocyte_II000371.tif\n",
      "Copied: 0.67_echinocyte_II000392.tif\n",
      "Copied: 0.67_echinocyte_II000382.tif\n",
      "Copied: 0.67_echinocyte_II000375.tif\n",
      "Copied: 0.67_echinocyte_II000362.tif\n",
      "Copied: 0.67_echinocyte_II000378.tif\n",
      "Copied: 0.67_echinocyte_II000368.tif\n",
      "Copied: 0.67_echinocyte_II000374.tif\n",
      "Copied: 0.67_echinocyte_II000380.tif\n",
      "Copied: 0.67_echinocyte_II000377.tif\n",
      "Copied: 0.67_echinocyte_II000369.tif\n",
      "Copied: 0.67_echinocyte_II000386.tif\n",
      "Copied: 0.33_echinocyte_I000354.tif\n",
      "Copied: 0.67_echinocyte_II000365.tif\n",
      "Copied: 0.67_echinocyte_II000361.tif\n",
      "Copied: 0.67_echinocyte_II000364.tif\n",
      "Copied: 0.67_echinocyte_II000370.tif\n",
      "Copied: 0.67_echinocyte_II000363.tif\n",
      "Copied: 0.33_echinocyte_I000350.tif\n",
      "Copied: 0.33_echinocyte_I000357.tif\n",
      "Copied: 0.33_echinocyte_I000358.tif\n",
      "Copied: 0.33_echinocyte_I000348.tif\n",
      "Copied: 0.33_echinocyte_I000339.tif\n",
      "Copied: 0.33_echinocyte_I000340.tif\n",
      "Copied: 0.33_echinocyte_I000337.tif\n",
      "Copied: 0.33_echinocyte_I000346.tif\n",
      "Copied: 0.33_echinocyte_I000349.tif\n",
      "Copied: 0.33_echinocyte_I000344.tif\n",
      "Copied: 0.33_echinocyte_I000336.tif\n",
      "Copied: 0.33_echinocyte_I000341.tif\n",
      "Copied: 0.33_echinocyte_I000352.tif\n",
      "Copied: 0.33_echinocyte_I000324.tif\n",
      "Copied: 0.67_echinocyte_II000360.tif\n",
      "Copied: 0.67_echinocyte_II000359.tif\n",
      "Copied: 0.33_echinocyte_I000351.tif\n",
      "Copied: 0.33_echinocyte_I000356.tif\n",
      "Copied: 0.33_echinocyte_I000353.tif\n",
      "Copied: 0.33_echinocyte_I000343.tif\n",
      "Copied: 0.33_echinocyte_I000345.tif\n",
      "Copied: 0.33_echinocyte_I000335.tif\n",
      "Copied: 0.33_echinocyte_I000331.tif\n",
      "Copied: 0.33_echinocyte_I000325.tif\n",
      "Copied: 0.33_echinocyte_I000347.tif\n",
      "Copied: 0.33_echinocyte_I000323.tif\n",
      "Copied: 0.33_echinocyte_I000313.tif\n",
      "Copied: 0.33_echinocyte_I000329.tif\n",
      "Copied: 0.33_echinocyte_I000334.tif\n",
      "Copied: 0.33_echinocyte_I000327.tif\n",
      "Copied: 0.33_echinocyte_I000322.tif\n",
      "Copied: 0.33_echinocyte_I000342.tif\n",
      "All matching files have been copied to image/echinocyte. Total files copied: 292\n",
      "Copied: B_keratocytes000675.tif\n",
      "Copied: B_keratocytes000690.tif\n",
      "Copied: B_keratocytes000696.tif\n",
      "Copied: B_keratocytes000695.tif\n",
      "Copied: B_keratocytes000702.tif\n",
      "Copied: B_keratocytes000703.tif\n",
      "Copied: B_keratocytes000701.tif\n",
      "Copied: B_keratocytes000697.tif\n",
      "Copied: B_keratocytes000688.tif\n",
      "Copied: B_keratocytes000699.tif\n",
      "Copied: B_keratocytes000691.tif\n",
      "Copied: B_keratocytes000693.tif\n",
      "Copied: B_keratocytes000698.tif\n",
      "Copied: B_keratocytes000694.tif\n",
      "Copied: B_keratocytes000692.tif\n",
      "Copied: B_keratocytes000676.tif\n",
      "Copied: B_keratocytes000685.tif\n",
      "Copied: B_keratocytes000700.tif\n",
      "Copied: B_keratocytes000687.tif\n",
      "Copied: B_keratocytes000689.tif\n",
      "Copied: B_keratocytes000686.tif\n",
      "Copied: B_keratocytes000682.tif\n",
      "Copied: B_keratocytes000684.tif\n",
      "Copied: B_keratocytes000683.tif\n",
      "Copied: B_keratocytes000678.tif\n",
      "Copied: B_keratocytes000677.tif\n",
      "Copied: B_keratocytes000679.tif\n",
      "Copied: B_keratocytes000680.tif\n",
      "Copied: B_keratocytes000674.tif\n",
      "Copied: B_keratocytes000681.tif\n",
      "Copied: B_keratocytes000673.tif\n",
      "All matching files have been copied to image/keratocytes. Total files copied: 31\n",
      "Copied: D_multilobate_cells000732.tif\n",
      "Copied: D_multilobate_cells000734.tif\n",
      "Copied: D_multilobate_cells000731.tif\n",
      "Copied: D_multilobate_cells000733.tif\n",
      "Copied: D_multilobate_cells000735.tif\n",
      "Copied: D_multilobate_cells000738.tif\n",
      "Copied: D_multilobate_cells000737.tif\n",
      "Copied: D_multilobate_cells000727.tif\n",
      "Copied: D_multilobate_cells000730.tif\n",
      "Copied: D_multilobate_cells000728.tif\n",
      "Copied: D_multilobate_cells000736.tif\n",
      "Copied: D_multilobate_cells000729.tif\n",
      "All matching files have been copied to image/multilobate_cells. Total files copied: 12\n",
      "Copied: A_cell_clusters000667.tif\n",
      "Copied: A_cell_clusters000609.tif\n",
      "Copied: A_cell_clusters000647.tif\n",
      "Copied: A_cell_clusters000638.tif\n",
      "Copied: A_cell_clusters000650.tif\n",
      "Copied: A_cell_clusters000621.tif\n",
      "Copied: A_cell_clusters000608.tif\n",
      "Copied: A_cell_clusters000619.tif\n",
      "Copied: A_cell_clusters000610.tif\n",
      "Copied: A_cell_clusters000620.tif\n",
      "Copied: A_cell_clusters000668.tif\n",
      "Copied: A_cell_clusters000663.tif\n",
      "Copied: A_cell_clusters000662.tif\n",
      "Copied: A_cell_clusters000661.tif\n",
      "Copied: A_cell_clusters000666.tif\n",
      "Copied: A_cell_clusters000649.tif\n",
      "Copied: A_cell_clusters000660.tif\n",
      "Copied: A_cell_clusters000654.tif\n",
      "Copied: A_cell_clusters000645.tif\n",
      "Copied: A_cell_clusters000665.tif\n",
      "Copied: A_cell_clusters000672.tif\n",
      "Copied: A_cell_clusters000670.tif\n",
      "Copied: A_cell_clusters000669.tif\n",
      "Copied: A_cell_clusters000664.tif\n",
      "Copied: A_cell_clusters000658.tif\n",
      "Copied: A_cell_clusters000652.tif\n",
      "Copied: A_cell_clusters000643.tif\n",
      "Copied: A_cell_clusters000646.tif\n",
      "Copied: A_cell_clusters000644.tif\n",
      "Copied: A_cell_clusters000657.tif\n",
      "Copied: A_cell_clusters000659.tif\n",
      "Copied: A_cell_clusters000656.tif\n",
      "Copied: A_cell_clusters000634.tif\n",
      "Copied: A_cell_clusters000653.tif\n",
      "Copied: A_cell_clusters000641.tif\n",
      "Copied: A_cell_clusters000637.tif\n",
      "Copied: A_cell_clusters000655.tif\n",
      "Copied: A_cell_clusters000651.tif\n",
      "Copied: A_cell_clusters000648.tif\n",
      "Copied: A_cell_clusters000630.tif\n",
      "Copied: A_cell_clusters000618.tif\n",
      "Copied: A_cell_clusters000614.tif\n",
      "Copied: A_cell_clusters000631.tif\n",
      "Copied: A_cell_clusters000616.tif\n",
      "Copied: A_cell_clusters000612.tif\n",
      "Copied: A_cell_clusters000607.tif\n",
      "Copied: A_cell_clusters000605.tif\n",
      "Copied: A_cell_clusters000617.tif\n",
      "Copied: A_cell_clusters000622.tif\n",
      "Copied: A_cell_clusters000606.tif\n",
      "Copied: A_cell_clusters000633.tif\n",
      "Copied: A_cell_clusters000632.tif\n",
      "Copied: A_cell_clusters000642.tif\n",
      "Copied: A_cell_clusters000640.tif\n",
      "Copied: A_cell_clusters000624.tif\n",
      "Copied: A_cell_clusters000629.tif\n",
      "Copied: A_cell_clusters000639.tif\n",
      "Copied: A_cell_clusters000627.tif\n",
      "Copied: A_cell_clusters000636.tif\n",
      "Copied: A_cell_clusters000628.tif\n",
      "Copied: A_cell_clusters000626.tif\n",
      "Copied: A_cell_clusters000635.tif\n",
      "Copied: A_cell_clusters000623.tif\n",
      "Copied: A_cell_clusters000625.tif\n",
      "Copied: A_cell_clusters000615.tif\n",
      "Copied: A_cell_clusters000611.tif\n",
      "Copied: A_cell_clusters000613.tif\n",
      "Copied: A_cell_clusters000604.tif\n",
      "Copied: A_cell_clusters000671.tif\n",
      "All matching files have been copied to image/cell_clusters. Total files copied: 69\n",
      "Copied: C_knizocytes000726.tif\n",
      "Copied: C_knizocytes000725.tif\n",
      "Copied: C_knizocytes000722.tif\n",
      "Copied: C_knizocytes000717.tif\n",
      "Copied: C_knizocytes000721.tif\n",
      "Copied: C_knizocytes000723.tif\n",
      "Copied: C_knizocytes000718.tif\n",
      "Copied: C_knizocytes000716.tif\n",
      "Copied: C_knizocytes000712.tif\n",
      "Copied: C_knizocytes000711.tif\n",
      "Copied: C_knizocytes000713.tif\n",
      "Copied: C_knizocytes000704.tif\n",
      "Copied: C_knizocytes000705.tif\n",
      "Copied: C_knizocytes000709.tif\n",
      "Copied: C_knizocytes000724.tif\n",
      "Copied: C_knizocytes000720.tif\n",
      "Copied: C_knizocytes000719.tif\n",
      "Copied: C_knizocytes000715.tif\n",
      "Copied: C_knizocytes000714.tif\n",
      "Copied: C_knizocytes000710.tif\n",
      "Copied: C_knizocytes000707.tif\n",
      "Copied: C_knizocytes000708.tif\n",
      "Copied: C_knizocytes000706.tif\n",
      "All matching files have been copied to image/knizocytes. Total files copied: 23\n",
      "Copied: D_multilobate_cells000732.tif\n",
      "Copied: D_multilobate_cells000734.tif\n",
      "Copied: D_multilobate_cells000731.tif\n",
      "Copied: D_multilobate_cells000733.tif\n",
      "Copied: D_multilobate_cells000735.tif\n",
      "Copied: D_multilobate_cells000738.tif\n",
      "Copied: D_multilobate_cells000737.tif\n",
      "Copied: D_multilobate_cells000727.tif\n",
      "Copied: D_multilobate_cells000730.tif\n",
      "Copied: D_multilobate_cells000728.tif\n",
      "Copied: D_multilobate_cells000736.tif\n",
      "Copied: D_multilobate_cells000729.tif\n",
      "All matching files have been copied to image/multilobate_cells. Total files copied: 12\n",
      "Copied: E_acanthocytes000804.tif\n",
      "Copied: E_acanthocytes000817.tif\n",
      "Copied: E_acanthocytes000773.tif\n",
      "Copied: E_acanthocytes000769.tif\n",
      "Copied: E_acanthocytes000758.tif\n",
      "Copied: E_acanthocytes000782.tif\n",
      "Copied: E_acanthocytes000823.tif\n",
      "Copied: E_acanthocytes000776.tif\n",
      "Copied: E_acanthocytes000820.tif\n",
      "Copied: E_acanthocytes000826.tif\n",
      "Copied: E_acanthocytes000821.tif\n",
      "Copied: E_acanthocytes000822.tif\n",
      "Copied: E_acanthocytes000818.tif\n",
      "Copied: E_acanthocytes000812.tif\n",
      "Copied: E_acanthocytes000801.tif\n",
      "Copied: E_acanthocytes000814.tif\n",
      "Copied: E_acanthocytes000825.tif\n",
      "Copied: E_acanthocytes000810.tif\n",
      "Copied: E_acanthocytes000809.tif\n",
      "Copied: E_acanthocytes000806.tif\n",
      "Copied: E_acanthocytes000815.tif\n",
      "Copied: E_acanthocytes000816.tif\n",
      "Copied: E_acanthocytes000805.tif\n",
      "Copied: E_acanthocytes000803.tif\n",
      "Copied: E_acanthocytes000811.tif\n",
      "Copied: E_acanthocytes000802.tif\n",
      "Copied: E_acanthocytes000824.tif\n",
      "Copied: E_acanthocytes000808.tif\n",
      "Copied: E_acanthocytes000807.tif\n",
      "Copied: E_acanthocytes000800.tif\n",
      "Copied: E_acanthocytes000798.tif\n",
      "Copied: E_acanthocytes000795.tif\n",
      "Copied: E_acanthocytes000813.tif\n",
      "Copied: E_acanthocytes000799.tif\n",
      "Copied: E_acanthocytes000794.tif\n",
      "Copied: E_acanthocytes000789.tif\n",
      "Copied: E_acanthocytes000791.tif\n",
      "Copied: E_acanthocytes000796.tif\n",
      "Copied: E_acanthocytes000783.tif\n",
      "Copied: E_acanthocytes000785.tif\n",
      "Copied: E_acanthocytes000787.tif\n",
      "Copied: E_acanthocytes000780.tif\n",
      "Copied: E_acanthocytes000790.tif\n",
      "Copied: E_acanthocytes000797.tif\n",
      "Copied: E_acanthocytes000793.tif\n",
      "Copied: E_acanthocytes000779.tif\n",
      "Copied: E_acanthocytes000792.tif\n",
      "Copied: E_acanthocytes000786.tif\n",
      "Copied: E_acanthocytes000788.tif\n",
      "Copied: E_acanthocytes000784.tif\n",
      "Copied: E_acanthocytes000781.tif\n",
      "Copied: E_acanthocytes000774.tif\n",
      "Copied: E_acanthocytes000775.tif\n",
      "Copied: E_acanthocytes000770.tif\n",
      "Copied: E_acanthocytes000771.tif\n",
      "Copied: E_acanthocytes000772.tif\n",
      "Copied: E_acanthocytes000764.tif\n",
      "Copied: E_acanthocytes000763.tif\n",
      "Copied: E_acanthocytes000778.tif\n",
      "Copied: E_acanthocytes000759.tif\n",
      "Copied: E_acanthocytes000777.tif\n",
      "Copied: E_acanthocytes000756.tif\n",
      "Copied: E_acanthocytes000768.tif\n",
      "Copied: E_acanthocytes000755.tif\n",
      "Copied: E_acanthocytes000766.tif\n",
      "Copied: E_acanthocytes000765.tif\n",
      "Copied: E_acanthocytes000757.tif\n",
      "Copied: E_acanthocytes000742.tif\n",
      "Copied: E_acanthocytes000740.tif\n",
      "Copied: E_acanthocytes000743.tif\n",
      "Copied: E_acanthocytes000748.tif\n",
      "Copied: E_acanthocytes000767.tif\n",
      "Copied: E_acanthocytes000753.tif\n",
      "Copied: E_acanthocytes000761.tif\n",
      "Copied: E_acanthocytes000760.tif\n",
      "Copied: E_acanthocytes000762.tif\n",
      "Copied: E_acanthocytes000752.tif\n",
      "Copied: E_acanthocytes000751.tif\n",
      "Copied: E_acanthocytes000749.tif\n",
      "Copied: E_acanthocytes000750.tif\n",
      "Copied: E_acanthocytes000754.tif\n",
      "Copied: E_acanthocytes000739.tif\n",
      "Copied: E_acanthocytes000746.tif\n",
      "Copied: E_acanthocytes000744.tif\n",
      "Copied: E_acanthocytes000747.tif\n",
      "Copied: E_acanthocytes000745.tif\n",
      "Copied: E_acanthocytes000741.tif\n",
      "Copied: E_acanthocytes000819.tif\n",
      "All matching files have been copied to image/acanthocytes. Total files copied: 88\n",
      "Copied: -0.33_stomatocyte_I000000.tif\n",
      "Copied: -0.67_stomatocyte_II000039.tif\n",
      "Copied: -0.33_stomatocyte_I000017.tif\n",
      "Copied: -0.33_stomatocyte_I000024.tif\n",
      "Copied: -0.33_stomatocyte_I000006.tif\n",
      "Copied: -0.67_stomatocyte_II000030.tif\n",
      "Copied: -0.33_stomatocyte_I000015.tif\n",
      "Copied: -0.33_stomatocyte_I000014.tif\n",
      "Copied: -0.67_stomatocyte_II000037.tif\n",
      "Copied: -0.33_stomatocyte_I000021.tif\n",
      "Copied: -0.67_stomatocyte_II000033.tif\n",
      "Copied: -0.67_stomatocyte_II000035.tif\n",
      "Copied: -0.33_stomatocyte_I000029.tif\n",
      "Copied: -0.33_stomatocyte_I000026.tif\n",
      "Copied: -0.33_stomatocyte_I000018.tif\n",
      "Copied: -0.67_stomatocyte_II000034.tif\n",
      "Copied: -0.67_stomatocyte_II000031.tif\n",
      "Copied: -0.33_stomatocyte_I000025.tif\n",
      "Copied: -0.33_stomatocyte_I000011.tif\n",
      "Copied: -0.33_stomatocyte_I000023.tif\n",
      "Copied: -0.33_stomatocyte_I000019.tif\n",
      "Copied: -0.33_stomatocyte_I000020.tif\n",
      "Copied: -0.67_stomatocyte_II000042.tif\n",
      "Copied: -0.33_stomatocyte_I000022.tif\n",
      "Copied: -0.33_stomatocyte_I000027.tif\n",
      "Copied: -0.67_stomatocyte_II000038.tif\n",
      "Copied: -0.33_stomatocyte_I000001.tif\n",
      "Copied: -0.67_stomatocyte_II000032.tif\n",
      "Copied: -0.33_stomatocyte_I000013.tif\n",
      "Copied: -0.67_stomatocyte_II000036.tif\n",
      "Copied: -0.33_stomatocyte_I000010.tif\n",
      "Copied: -0.33_stomatocyte_I000028.tif\n",
      "Copied: -0.33_stomatocyte_I000016.tif\n",
      "Copied: -0.33_stomatocyte_I000004.tif\n",
      "Copied: -0.33_stomatocyte_I000005.tif\n",
      "Copied: -0.33_stomatocyte_I000012.tif\n",
      "Copied: -0.33_stomatocyte_I000008.tif\n",
      "Copied: -0.33_stomatocyte_I000009.tif\n",
      "Copied: -0.33_stomatocyte_I000007.tif\n",
      "Copied: -0.33_stomatocyte_I000003.tif\n",
      "Copied: -0.33_stomatocyte_I000002.tif\n",
      "All matching files have been copied to image/stomatocyte. Total files copied: 41\n"
     ]
    }
   ],
   "source": [
    "image_path='image'\n",
    "def copy_files_by_pattern(directory_path, destination_path, regex_pattern):\n",
    "    \"\"\"\n",
    "    Copies files from the source directory to the destination directory based on a regex pattern.\n",
    "\n",
    "    Args:\n",
    "    directory_path (str): Path to the directory containing the files.\n",
    "    destination_path (str): Directory where the copies will be stored.\n",
    "    regex_pattern (str): Regular expression pattern to match filenames.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Compile the regex pattern\n",
    "    pattern = re.compile(regex_pattern)\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "    # Initialize a counter for copied files\n",
    "    copied_files_count = 0\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the filename matches the pattern\n",
    "        if pattern.match(filename):\n",
    "            # Path of the current file\n",
    "            current_file_path = os.path.join(directory_path, filename)\n",
    "            # Path where the file will be copied\n",
    "            destination_file_path = os.path.join(destination_path, filename)\n",
    "            # Copy the file\n",
    "            shutil.copy2(current_file_path, destination_file_path)\n",
    "            copied_files_count += 1\n",
    "            print(f'Copied: {filename}')\n",
    "\n",
    "    # Print the result\n",
    "    print(f'All matching files have been copied to {destination_path}. Total files copied: {copied_files_count}')\n",
    "\n",
    "\n",
    "cell_types = [\n",
    "    \"spherocyte\",\n",
    "    \"echinocyte\",\n",
    "    \"keratocytes\",\n",
    "    \"multilobate_cells\",\n",
    "    \"cell_clusters\",\n",
    "    \"knizocytes\",\n",
    "    \"multilobate_cells\",\n",
    "    \"acanthocytes\",\n",
    "    \"stomatocyte\"\n",
    "]\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    directory_path = image_path\n",
    "    destination_path = image_path + '/' + cell_type\n",
    "    regex_pattern = rf'.*{cell_type}.*\\.tif$'\n",
    "\n",
    "    copy_files_by_pattern(directory_path, destination_path, regex_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(inputs, patch_size, num_patches, projection_dim, return_patches=False):\n",
    "    patches = layers.Conv2D(filters=projection_dim, kernel_size=patch_size, strides=patch_size, padding=\"valid\")(inputs)\n",
    "    reshaped_patches = layers.Reshape((num_patches, projection_dim))(patches)\n",
    "    if return_patches:\n",
    "        return patches  # Return patches for visualization\n",
    "    return reshaped_patches\n",
    "\n",
    "def add_position_embedding(patches, num_patches, projection_dim):\n",
    "    position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)(tf.range(num_patches))\n",
    "    return patches + position_embedding\n",
    "\n",
    "def transformer_encoder(patches, projection_dim, num_heads, transformer_depth):\n",
    "    for _ in range(transformer_depth):\n",
    "        # Normalize the input patches\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(patches)\n",
    "        \n",
    "        # Apply Multi-Head Attention\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=0.1)(x1, x1)\n",
    "        \n",
    "        # Add the attention output back to the input (Skip Connection)\n",
    "        x2 = layers.Add()([attention_output, patches])\n",
    "        \n",
    "        # Normalize the result of the addition\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # Apply a feed-forward network (FFN) within the transformer, first expanding then projecting back\n",
    "        x3 = layers.Dense(units=projection_dim*2, activation=\"relu\")(x3)\n",
    "        patches = layers.Dense(units=projection_dim)(x3)\n",
    "        \n",
    "        # Add the output of the FFN back to the combined result of the attention output and the input (Second Skip Connection)\n",
    "        patches = layers.Add()([patches, x2])\n",
    "        \n",
    "    return patches\n",
    "\n",
    "def build_classifier(patches, num_classes):\n",
    "    # Normalize the input\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(patches)\n",
    "    \n",
    "    # Flatten the normalized tensor to prepare for the dense layer\n",
    "    representation = layers.Flatten()(representation)\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    features = layers.Dropout(0.5)(representation)\n",
    "    \n",
    "    # Dense layer for learning non-linear combinations\n",
    "    features = layers.Dense(128, activation=\"relu\")(features)\n",
    "    \n",
    "    # Another dropout for regularization\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    \n",
    "    # Final dense layer with softmax activation for classification\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def create_vit_classifier(input_shape, patch_size, num_patches, projection_dim, num_heads, transformer_depth, num_classes):\n",
    "    # Define the input layer with the specified input shape\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Extract patches from the input image and project to a higher-dimensional space\n",
    "    patches = create_patches(inputs, patch_size, num_patches, projection_dim)\n",
    "    \n",
    "    # Add positional embeddings to the patches to retain positional information\n",
    "    patches = add_position_embedding(patches, num_patches, projection_dim)\n",
    "    \n",
    "    # Pass the patches through the transformer encoder to process interactions between patches\n",
    "    patches = transformer_encoder(patches, projection_dim, num_heads, transformer_depth)\n",
    "    \n",
    "    # Build the classifier head to make final predictions from the encoded features\n",
    "    outputs = build_classifier(patches, num_classes)\n",
    "    \n",
    "    # Create the final Keras model with inputs as the image and outputs as the class predictions\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 523 images belonging to 8 classes.\n",
      "Found 126 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 04:09:02.942895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46676 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:21:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set paths to your data directories\n",
    "image_path='image'\n",
    "\n",
    "data_dir = image_path+'/Classes'\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,    # Normalize pixel values\n",
    "    validation_split=0.2,  # Reserve 20% for validation\n",
    "    rotation_range=20,  # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image \n",
    "    width_shift_range=0.1,  # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # Randomly flip images\n",
    "    vertical_flip=False,  # Do not randomly flip images vertically\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    brightness_range=[0.2,1.0],  # Range for picking a brightness shift value\n",
    "    fill_mode='nearest',  # Points outside the boundaries are filled according to the given mode\n",
    "    cval=0.0  # Value used for points outside the boundaries when fill_mode = \"constant\"\n",
    ")\n",
    "\n",
    "# Setup the train generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(64, 64),  # Load images at 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',  # Ensure this matches the loss function\n",
    "    subset='training',  # Set as training data\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Setup the validation generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(64, 64),  # Load images at 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',  # Ensure this matches the loss function\n",
    "    subset='validation',  # Set as validation data\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Convert the generators to tf.data.Dataset\n",
    "def generator_to_dataset(generator):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "train_dataset = generator_to_dataset(train_generator).repeat()\n",
    "validation_dataset = generator_to_dataset(validation_generator).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.920774647887324, 1: 1.1674107142857142, 2: 0.2793803418803419, 3: 2.615, 4: 3.4407894736842106, 5: 6.5375, 6: 0.8716666666666667, 7: 1.981060606060606}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Get the class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"Class weights:\", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 Complete [00h 00m 28s]\n",
      "val_accuracy: 0.1428571492433548\n",
      "\n",
      "Best val_accuracy So Far: 0.460317462682724\n",
      "Total elapsed time: 01h 03m 06s\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f258c42a490>\n"
     ]
    }
   ],
   "source": [
    "# Function to build the model for hyperparameter tuning\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "# Function to build the model for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    num_layers = hp.Int('num_layers', min_value=2, max_value=50, step=1)\n",
    "    num_heads = hp.Int('num_heads', min_value=4, max_value=50, step=2)\n",
    "    d_model = hp.Int('d_model', min_value=64, max_value=456, step=64)\n",
    "    transformer_depth = hp.Int('transformer_depth', min_value=2, max_value=6, step=1)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    model = create_vit_classifier(\n",
    "        input_shape=(64, 64, 3),\n",
    "        patch_size=8,\n",
    "        num_patches=(64 // 8) ** 2,\n",
    "        projection_dim=d_model,\n",
    "        num_heads=num_heads,\n",
    "        transformer_depth=transformer_depth,\n",
    "        num_classes=8\n",
    "    )\n",
    "    \n",
    "    lr = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Custom callback to stop training if accuracy is below a threshold after a specific number of epochs\n",
    "class EarlyStoppingByAccuracyAfterNEpochs(Callback):\n",
    "    def __init__(self, monitor='accuracy', value=0.45, patience=7, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_count += 1\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if self.epoch_count >= self.patience:\n",
    "            if acc is not None and acc < self.value:\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Epoch {epoch}: early stopping threshold reached: {acc} < {self.value}\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "\n",
    "# Initialize the RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=80,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir_new',\n",
    "    project_name='hparam_tuning_new'\n",
    ")\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStoppingByAccuracyAfterNEpochs(monitor='accuracy', value=0.45, verbose=1)\n",
    "\n",
    "\n",
    "# Perform the hyperparameter search with class weights and the custom callback\n",
    "tuner.search(train_generator, \n",
    "             epochs=10, \n",
    "             validation_data=validation_generator, \n",
    "             class_weight=class_weights_dict,\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "# Retrieve the best hyperparameters and print them\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of layers is 4.\n",
      "The optimal number of heads is 16.\n",
      "The optimal projection dimension is 384.\n",
      "The optimal transformer depth is 2.\n",
      "The optimal dropout rate is 0.5.\n",
      "The optimal learning rate is 0.0003699594136815919.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters and print them\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of heads is {best_hps.get('num_heads')}.\n",
    "The optimal projection dimension is {best_hps.get('d_model')}.\n",
    "The optimal transformer depth is {best_hps.get('transformer_depth')}.\n",
    "The optimal dropout rate is {best_hps.get('dropout_rate')}.\n",
    "The optimal learning rate is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_params = {\n",
    "    \"num_layers\": 4,\n",
    "    \"num_heads\": 16,\n",
    "    \"d_model\": 384,\n",
    "    \"mlp_dim\": 2,\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"learning_rate\": 0.0003699594136815919\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "input_shape = (64, 64, 3)  # Assuming RGB images of size 64x64\n",
    "patch_size = 4  # Patch size: 4x4\n",
    "num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
    "projection_dim = trial_params[\"d_model\"]\n",
    "num_heads = trial_params[\"num_heads\"]\n",
    "transformer_depth = trial_params[\"num_layers\"]\n",
    "#mlp_dim = trial_params[\"mlp_dim\"]\n",
    "dropout_rate = trial_params[\"dropout_rate\"]\n",
    "learning_rate = trial_params[\"learning_rate\"]\n",
    "num_classes = len(train_generator.class_indices)  # Number of classes based on the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 384)          18816     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 256, 384)             0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)  (None, 256, 384)             0         ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 256, 384)             768       ['tf.math.add_1[0][0]']       \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 256, 384)             9456000   ['layer_normalization_13[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 256, 384)             0         ['multi_head_attention_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.math.add_1[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 256, 384)             768       ['add_12[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 256, 768)             295680    ['layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 256, 384)             295296    ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 256, 384)             0         ['dense_15[0][0]',            \n",
      "                                                                     'add_12[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 256, 384)             768       ['add_13[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 256, 384)             9456000   ['layer_normalization_15[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 256, 384)             0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_13[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 256, 384)             768       ['add_14[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 256, 768)             295680    ['layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 256, 384)             295296    ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 256, 384)             0         ['dense_17[0][0]',            \n",
      "                                                                     'add_14[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 256, 384)             768       ['add_15[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 256, 384)             9456000   ['layer_normalization_17[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 256, 384)             0         ['multi_head_attention_8[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_15[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, 256, 384)             768       ['add_16[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 256, 768)             295680    ['layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 256, 384)             295296    ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 256, 384)             0         ['dense_19[0][0]',            \n",
      "                                                                     'add_16[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, 256, 384)             768       ['add_17[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, 256, 384)             9456000   ['layer_normalization_19[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 256, 384)             0         ['multi_head_attention_9[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_17[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_20 (La  (None, 256, 384)             768       ['add_18[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 256, 768)             295680    ['layer_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 256, 384)             295296    ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 256, 384)             0         ['dense_21[0][0]',            \n",
      "                                                                     'add_18[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_21 (La  (None, 256, 384)             768       ['add_19[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 98304)                0         ['layer_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 98304)                0         ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 128)                  1258304   ['dropout_2[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128)                  0         ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 8)                    1032      ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52797704 (201.41 MB)\n",
      "Trainable params: 52797704 (201.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_vit_classifier(input_shape, patch_size, num_patches, projection_dim, num_heads, transformer_depth, num_classes)\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 1.9147 - accuracy: 0.4455 - val_loss: 1.8870 - val_accuracy: 0.5079\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.9128 - accuracy: 0.4570 - val_loss: 1.9083 - val_accuracy: 0.4524\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 3s 165ms/step - loss: 1.9059 - accuracy: 0.4532 - val_loss: 1.9022 - val_accuracy: 0.4603\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.9167 - accuracy: 0.4264 - val_loss: 1.8989 - val_accuracy: 0.4603\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.8980 - accuracy: 0.4685 - val_loss: 1.8798 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.9092 - accuracy: 0.4302 - val_loss: 1.9127 - val_accuracy: 0.4365\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.8916 - accuracy: 0.4532 - val_loss: 1.8910 - val_accuracy: 0.4603\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 3s 167ms/step - loss: 1.8921 - accuracy: 0.4665 - val_loss: 1.8887 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 3s 163ms/step - loss: 1.8982 - accuracy: 0.4379 - val_loss: 1.8961 - val_accuracy: 0.4444\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 2s 148ms/step - loss: 1.8951 - accuracy: 0.4436 - val_loss: 1.8575 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 2s 147ms/step - loss: 1.8953 - accuracy: 0.4302 - val_loss: 1.8804 - val_accuracy: 0.4603\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 2s 147ms/step - loss: 1.8785 - accuracy: 0.4723 - val_loss: 1.8946 - val_accuracy: 0.4127\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.8900 - accuracy: 0.4302 - val_loss: 1.9002 - val_accuracy: 0.4127\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.8746 - accuracy: 0.4570 - val_loss: 1.8458 - val_accuracy: 0.5079\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.8827 - accuracy: 0.4398 - val_loss: 1.8701 - val_accuracy: 0.4603\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.8737 - accuracy: 0.4570 - val_loss: 1.8693 - val_accuracy: 0.4524\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.8795 - accuracy: 0.4436 - val_loss: 1.8804 - val_accuracy: 0.4444\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 3s 166ms/step - loss: 1.8706 - accuracy: 0.4417 - val_loss: 1.8437 - val_accuracy: 0.4921\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.8620 - accuracy: 0.4646 - val_loss: 1.8600 - val_accuracy: 0.4603\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.8755 - accuracy: 0.4302 - val_loss: 1.8717 - val_accuracy: 0.4365\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.8620 - accuracy: 0.4532 - val_loss: 1.8515 - val_accuracy: 0.4524\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 3s 167ms/step - loss: 1.8639 - accuracy: 0.4474 - val_loss: 1.8561 - val_accuracy: 0.4603\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.8614 - accuracy: 0.4512 - val_loss: 1.8503 - val_accuracy: 0.4603\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.8550 - accuracy: 0.4359 - val_loss: 1.8331 - val_accuracy: 0.4683\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.8570 - accuracy: 0.4570 - val_loss: 1.8504 - val_accuracy: 0.4762\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.8599 - accuracy: 0.4321 - val_loss: 1.8116 - val_accuracy: 0.5079\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 3s 167ms/step - loss: 1.8367 - accuracy: 0.4723 - val_loss: 1.8408 - val_accuracy: 0.4603\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 3s 154ms/step - loss: 1.8542 - accuracy: 0.4398 - val_loss: 1.8310 - val_accuracy: 0.4841\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.8600 - accuracy: 0.4359 - val_loss: 1.8617 - val_accuracy: 0.4127\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 2s 148ms/step - loss: 1.8374 - accuracy: 0.4512 - val_loss: 1.8289 - val_accuracy: 0.4603\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 3s 148ms/step - loss: 1.8392 - accuracy: 0.4493 - val_loss: 1.8317 - val_accuracy: 0.4603\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.8421 - accuracy: 0.4436 - val_loss: 1.8184 - val_accuracy: 0.4762\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 3s 154ms/step - loss: 1.8357 - accuracy: 0.4493 - val_loss: 1.8180 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 3s 154ms/step - loss: 1.8425 - accuracy: 0.4455 - val_loss: 1.8488 - val_accuracy: 0.4127\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.8165 - accuracy: 0.4704 - val_loss: 1.8229 - val_accuracy: 0.4603\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 1.8474 - accuracy: 0.4264 - val_loss: 1.8478 - val_accuracy: 0.4048\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.8307 - accuracy: 0.4512 - val_loss: 1.8158 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 2s 148ms/step - loss: 1.8255 - accuracy: 0.4436 - val_loss: 1.7968 - val_accuracy: 0.4762\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.8232 - accuracy: 0.4532 - val_loss: 1.8144 - val_accuracy: 0.4603\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 3s 165ms/step - loss: 1.8322 - accuracy: 0.4398 - val_loss: 1.8088 - val_accuracy: 0.4683\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.8128 - accuracy: 0.4608 - val_loss: 1.8007 - val_accuracy: 0.4841\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.8195 - accuracy: 0.4398 - val_loss: 1.8264 - val_accuracy: 0.4444\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.8199 - accuracy: 0.4474 - val_loss: 1.8061 - val_accuracy: 0.4603\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.8076 - accuracy: 0.4589 - val_loss: 1.7921 - val_accuracy: 0.4921\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.8217 - accuracy: 0.4398 - val_loss: 1.7780 - val_accuracy: 0.4683\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.8131 - accuracy: 0.4512 - val_loss: 1.8271 - val_accuracy: 0.4365\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 3s 163ms/step - loss: 1.8107 - accuracy: 0.4436 - val_loss: 1.7982 - val_accuracy: 0.4603\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.8098 - accuracy: 0.4474 - val_loss: 1.7994 - val_accuracy: 0.4603\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.8031 - accuracy: 0.4512 - val_loss: 1.7784 - val_accuracy: 0.4683\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 3s 166ms/step - loss: 1.8097 - accuracy: 0.4436 - val_loss: 1.8047 - val_accuracy: 0.4524\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.8053 - accuracy: 0.4379 - val_loss: 1.7906 - val_accuracy: 0.4603\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 3s 154ms/step - loss: 1.8142 - accuracy: 0.4379 - val_loss: 1.7832 - val_accuracy: 0.4683\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 2s 146ms/step - loss: 1.7785 - accuracy: 0.4761 - val_loss: 1.8014 - val_accuracy: 0.4444\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 3s 169ms/step - loss: 1.8042 - accuracy: 0.4302 - val_loss: 1.7879 - val_accuracy: 0.4444\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.8049 - accuracy: 0.4417 - val_loss: 1.7831 - val_accuracy: 0.4603\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.7941 - accuracy: 0.4512 - val_loss: 1.7963 - val_accuracy: 0.4524\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.7906 - accuracy: 0.4532 - val_loss: 1.7824 - val_accuracy: 0.4762\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 3s 163ms/step - loss: 1.7816 - accuracy: 0.4474 - val_loss: 1.7884 - val_accuracy: 0.4524\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 3s 163ms/step - loss: 1.7937 - accuracy: 0.4455 - val_loss: 1.7762 - val_accuracy: 0.4603\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.7952 - accuracy: 0.4398 - val_loss: 1.7880 - val_accuracy: 0.4762\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.7862 - accuracy: 0.4474 - val_loss: 1.7503 - val_accuracy: 0.4683\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.7804 - accuracy: 0.4532 - val_loss: 1.7948 - val_accuracy: 0.4286\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.7714 - accuracy: 0.4627 - val_loss: 1.7694 - val_accuracy: 0.4603\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.7937 - accuracy: 0.4302 - val_loss: 1.7441 - val_accuracy: 0.4921\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.7706 - accuracy: 0.4627 - val_loss: 1.7666 - val_accuracy: 0.4762\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.7743 - accuracy: 0.4474 - val_loss: 1.7645 - val_accuracy: 0.4524\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.7830 - accuracy: 0.4436 - val_loss: 1.7631 - val_accuracy: 0.4603\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.7760 - accuracy: 0.4436 - val_loss: 1.7154 - val_accuracy: 0.5079\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.7744 - accuracy: 0.4493 - val_loss: 1.7816 - val_accuracy: 0.4286\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 1.7754 - accuracy: 0.4474 - val_loss: 1.7579 - val_accuracy: 0.4683\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.7664 - accuracy: 0.4512 - val_loss: 1.7568 - val_accuracy: 0.4603\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.7787 - accuracy: 0.4379 - val_loss: 1.7993 - val_accuracy: 0.4127\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.7779 - accuracy: 0.4359 - val_loss: 1.7835 - val_accuracy: 0.4048\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 1.7621 - accuracy: 0.4570 - val_loss: 1.7163 - val_accuracy: 0.5079\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.7534 - accuracy: 0.4551 - val_loss: 1.7509 - val_accuracy: 0.4603\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 3s 164ms/step - loss: 1.7669 - accuracy: 0.4436 - val_loss: 1.7846 - val_accuracy: 0.4206\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.7680 - accuracy: 0.4455 - val_loss: 1.6968 - val_accuracy: 0.5079\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.7615 - accuracy: 0.4436 - val_loss: 1.7532 - val_accuracy: 0.4444\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 3s 167ms/step - loss: 1.7540 - accuracy: 0.4589 - val_loss: 1.7451 - val_accuracy: 0.4603\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.7607 - accuracy: 0.4455 - val_loss: 1.7947 - val_accuracy: 0.4048\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 3s 154ms/step - loss: 1.7513 - accuracy: 0.4512 - val_loss: 1.7177 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 3s 151ms/step - loss: 1.7692 - accuracy: 0.4379 - val_loss: 1.7618 - val_accuracy: 0.4683\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 3s 149ms/step - loss: 1.7451 - accuracy: 0.4551 - val_loss: 1.7396 - val_accuracy: 0.4603\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.7731 - accuracy: 0.4302 - val_loss: 1.7304 - val_accuracy: 0.4683\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.7383 - accuracy: 0.4646 - val_loss: 1.7627 - val_accuracy: 0.4444\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.7523 - accuracy: 0.4436 - val_loss: 1.7579 - val_accuracy: 0.4365\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 2s 148ms/step - loss: 1.7675 - accuracy: 0.4245 - val_loss: 1.7344 - val_accuracy: 0.4603\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 3s 154ms/step - loss: 1.7329 - accuracy: 0.4685 - val_loss: 1.7662 - val_accuracy: 0.4365\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.7415 - accuracy: 0.4570 - val_loss: 1.7209 - val_accuracy: 0.4524\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.7660 - accuracy: 0.4359 - val_loss: 1.7125 - val_accuracy: 0.4841\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.7331 - accuracy: 0.4493 - val_loss: 1.7294 - val_accuracy: 0.4603\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 3s 165ms/step - loss: 1.7415 - accuracy: 0.4474 - val_loss: 1.7102 - val_accuracy: 0.4683\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 2s 146ms/step - loss: 1.7390 - accuracy: 0.4551 - val_loss: 1.6989 - val_accuracy: 0.4921\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 3s 166ms/step - loss: 1.7558 - accuracy: 0.4340 - val_loss: 1.7394 - val_accuracy: 0.4286\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.7413 - accuracy: 0.4436 - val_loss: 1.7247 - val_accuracy: 0.4603\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.7222 - accuracy: 0.4665 - val_loss: 1.7475 - val_accuracy: 0.4127\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 3s 151ms/step - loss: 1.7570 - accuracy: 0.4302 - val_loss: 1.7386 - val_accuracy: 0.4603\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.7382 - accuracy: 0.4455 - val_loss: 1.6525 - val_accuracy: 0.5317\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.7283 - accuracy: 0.4570 - val_loss: 1.7201 - val_accuracy: 0.4603\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.7444 - accuracy: 0.4398 - val_loss: 1.7164 - val_accuracy: 0.4683\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=100,  # Increased number of epochs\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    validation_steps=len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vision_transformer_model_regularization_vitimageclassificationcopy.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 130ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     acanthocytes       0.00      0.00      0.00        17\n",
      "    cell_clusters       0.00      0.00      0.00        13\n",
      "       echinocyte       0.46      1.00      0.63        58\n",
      "      keratocytes       0.00      0.00      0.00         6\n",
      "       knizocytes       0.00      0.00      0.00         4\n",
      "multilobate_cells       0.00      0.00      0.00         2\n",
      "       spherocyte       0.00      0.00      0.00        18\n",
      "      stomatocyte       0.00      0.00      0.00         8\n",
      "\n",
      "         accuracy                           0.46       126\n",
      "        macro avg       0.06      0.12      0.08       126\n",
      "     weighted avg       0.21      0.46      0.29       126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "validation_steps = len(validation_generator)\n",
    "predictions = model.predict(validation_generator, steps=validation_steps)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution: [ 71  56 234  25  19  10  75  33]\n",
      "Validation class distribution: [17 13 58  6  4  2 18  8]\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of classes in the training and validation sets\n",
    "train_class_counts = np.bincount(train_generator.classes)\n",
    "val_class_counts = np.bincount(validation_generator.classes)\n",
    "\n",
    "print(\"Training class distribution:\", train_class_counts)\n",
    "print(\"Validation class distribution:\", val_class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
